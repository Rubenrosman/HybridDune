{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6f6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for importing netcdf, finding optimal shuffle settings for encoding, and then saving the dataset with these settings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os   \n",
    "import copy\n",
    "import re\n",
    "from get_optimal_shuffle_encoding import get_optimal_shuffle_encoding\n",
    "\n",
    "# load the dataset\n",
    "folder_in = r'O:\\HybridDune experiment\\data ADV, OBS\\raw NetCDF\\test'\n",
    "filename_in = r'ADV_RWS1_Deployment1.nc'\n",
    "filename_out_shuffle_optimal = re.sub(r'\\.nc$', ' shuffle_optimal V2.nc', filename_in)  # subtract .nc from filename, add ' shuffle_optimal.nc'\n",
    "filename_1var_shuffle_off = r'temp 1var shuffle_off' \n",
    "filename_1var_shuffle_on  = r'temp 1var shuffle_on'  \n",
    "filename_out_shuffle_off = r'ADV_RWS1_Deployment1 shuffle_off.nc'\n",
    "filename_out_shuffle_on  = r'ADV_RWS1_Deployment1 shuffle_on.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant 1: open dataset and explicitly define scaling settings\n",
    "ds = xr.open_dataset(os.path.join(folder_in, filename_in))\n",
    "# Change data type of ds.p from int64 to float64 (otherwise the NETCDF scaling gives an error)\n",
    "ds['p'] = ds['p'].astype('float64')\n",
    "\n",
    "# Save the dataset to netCDF --------------------------------------------------------\n",
    "# First define a custom encoding dictionary for the ADV variables, to save variables with the same accuracy (same number of decimals) as the original text file with data\n",
    "encoding = {'p': { 'scale_factor': 10., 'dtype': 'int16', '_FillValue': -999},\n",
    "            'u': { 'scale_factor': 0.001, 'dtype': 'int16', '_FillValue': -999},  # three decimals originally, so scale factor 0.001. max value is 7m/s, with 3 decimals is 7000 options, so int16 scale of Â± 32767 is sufficient\n",
    "            'v': { 'scale_factor': 0.001, 'dtype': 'int16', '_FillValue': -999},  # shuffle: flag for bit order. I just tried for which variables it saves data. (default is True when using deflate compression)\n",
    "            'w': { 'scale_factor': 0.001, 'dtype': 'int16', '_FillValue': -999},\n",
    "            'anl1': { 'dtype': 'uint16'},\n",
    "            'anl2': { 'dtype': 'uint16'},\n",
    "            'a1': { 'dtype': 'int16', '_FillValue': -999},\n",
    "            'a2': { 'dtype': 'int16', '_FillValue': -999},\n",
    "            'a3': { 'dtype': 'int16', '_FillValue': -999},\n",
    "            'cor1': { 'dtype': 'int8', '_FillValue': -99},\n",
    "            'cor2': { 'dtype': 'int8', '_FillValue': -99},\n",
    "            'cor3': { 'dtype': 'int8', '_FillValue': -99},\n",
    "            'snr1': { 'scale_factor': 0.1, 'dtype': 'int16', '_FillValue': -999},\n",
    "            'snr2': { 'scale_factor': 0.1, 'dtype': 'int16', '_FillValue': -999},\n",
    "            'snr3': { 'scale_factor': 0.1, 'dtype': 'int16', '_FillValue': -999},\n",
    "            'voltage': { 'scale_factor': 0.1, 'dtype': 'int16', '_FillValue': -999},\n",
    "            'heading': { 'scale_factor': 0.1, 'dtype': 'int16', '_FillValue': -999},\n",
    "            'pitch': { 'scale_factor': 0.1, 'dtype': 'int16', '_FillValue': -999},\n",
    "            'roll': { 'scale_factor': 0.1, 'dtype': 'int16', '_FillValue': -999},\n",
    "            'burst': { 'scale_factor': 0.1, 'dtype': 'int16', '_FillValue': -999} }\n",
    "\n",
    "encoding_shuffle_off = copy.deepcopy(encoding)  # make a copy of the encoding dict, to add the shuffle setting\n",
    "encoding_shuffle_on  = copy.deepcopy(encoding)\n",
    "\n",
    "# Then add deflate compression level 4 to all variables and coordinates in netCDF, without overwriting existing keys\n",
    "compression_shuffle_off = {var: {\"zlib\": True, \"complevel\": 4, 'shuffle': False} for var in list(ds.data_vars) + list(ds.coords)}  # temporary dict, with only compression settings\n",
    "compression_shuffle_on  = {var: {\"zlib\": True, \"complevel\": 4, 'shuffle': True} for var in list(ds.data_vars) + list(ds.coords)}  # temporary dict, with only compression settings\n",
    "\n",
    "for var, comp in compression_shuffle_off.items():  # for each variable in the dataset, \n",
    "    if var in encoding_shuffle_off:                # if the variable already has an encoding, update it with the compression settings\n",
    "        encoding_shuffle_off[var].update(comp)\n",
    "    else:                                          # if the variable does not have an encoding yet, add it \n",
    "        encoding_shuffle_off[var] = comp\n",
    "\n",
    "for var, comp in compression_shuffle_on.items():  # for each variable in the dataset, \n",
    "    if var in encoding_shuffle_on:                # if the variable already has an encoding, update it with the compression settings\n",
    "        encoding_shuffle_on[var].update(comp)\n",
    "    else:                                          # if the variable does not have an encoding yet, add it \n",
    "        encoding_shuffle_on[var] = comp\n",
    "\n",
    "#print(encoding_shuffle_off)   # print the compression settings to check\n",
    "#print(encoding_shuffle_on)    # print the compression settings to check\n",
    "#ds.to_netcdf(os.path.join(folder_in, filename_out_shuffle_off), encoding=encoding_shuffle_off)\n",
    "#ds.to_netcdf(os.path.join(folder_in, filename_out_shuffle_on), encoding=encoding_shuffle_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1113439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding found in dataset starts with 'unlimited dims:', is likely default/not useful. Skipped, instead only using deflate compression. Encoding found: {'unlimited_dims': set(), 'source': 'O:\\\\HybridDune experiment\\\\data ADV, OBS\\\\raw NetCDF\\\\test\\\\ADV_RWS1_Deployment1.nc'}\n",
      "{'sf': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'p': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'u': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'v': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'w': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'anl1': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'anl2': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'a1': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'a2': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'a3': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'cor1': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'cor2': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'cor3': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'snr1': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'snr2': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'snr3': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'voltage': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'heading': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'pitch': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'roll': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'burst': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'pm': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'um': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'vm': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'wm': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'anl1m': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'anl2m': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'cor1m': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'cor2m': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'cor3m': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'snr1m': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'snr2m': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'snr3m': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'headingm': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'pitchm': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'rollm': {'zlib': True, 'complevel': 4, 'shuffle': False}, 't': {'zlib': True, 'complevel': 4, 'shuffle': False}, 'N': {'zlib': True, 'complevel': 4, 'shuffle': False}}\n",
      "{'sf': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'p': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'u': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'v': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'w': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'anl1': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'anl2': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'a1': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'a2': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'a3': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'cor1': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'cor2': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'cor3': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'snr1': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'snr2': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'snr3': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'voltage': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'heading': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'pitch': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'roll': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'burst': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'pm': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'um': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'vm': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'wm': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'anl1m': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'anl2m': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'cor1m': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'cor2m': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'cor3m': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'snr1m': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'snr2m': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'snr3m': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'headingm': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'pitchm': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'rollm': {'zlib': True, 'complevel': 4, 'shuffle': True}, 't': {'zlib': True, 'complevel': 4, 'shuffle': True}, 'N': {'zlib': True, 'complevel': 4, 'shuffle': True}}\n"
     ]
    }
   ],
   "source": [
    "# Variant 2: open dataset and load encoding from the dataset, if possible\n",
    "ds = xr.open_dataset(os.path.join(folder_in, filename_in))\n",
    "\n",
    "# Define two dictionaries for compression settings, one with shuffle on and one with shuffle off\n",
    "compression_shuffle_off = {var: {\"zlib\": True, \"complevel\": 4, 'shuffle': False} for var in list(ds.data_vars) + list(ds.coords)}  \n",
    "compression_shuffle_on  = {var: {\"zlib\": True, \"complevel\": 4, 'shuffle': True} for var in list(ds.data_vars) + list(ds.coords)}  \n",
    "\n",
    "# use ds.encoding from the dataset, if possible\n",
    "# NB: if no user-defined encoding is saved in the dataset, it (often?) contains a dict (starting with 'unlimited_dims=set()' ) that is not useful. Check if that's the case\n",
    "if hasattr(ds, 'encoding') and list(encoding.keys())[0] != 'unlimited_dims':  # If useful encoding is found in the dataset\n",
    "    encoding = ds.encoding  # load the encoding from the dataset    \n",
    "    encoding_shuffle_off = copy.deepcopy(encoding)  # make a copy of the encoding dict, to add the shuffle setting\n",
    "    encoding_shuffle_on  = copy.deepcopy(encoding)\n",
    "    print (f'Encoding found in dataset: {encoding}')  # print the encoding to check\n",
    "\n",
    "    # Then add deflate compression to all variables and coordinates in netCDF, without overwriting existing keys\n",
    "    for var, comp in compression_shuffle_off.items():  # for each variable in the dataset, \n",
    "        if var in encoding_shuffle_off:                # if the variable already has an encoding, update it with the compression settings\n",
    "            encoding_shuffle_off[var].update(comp)\n",
    "        else:                                          # if the variable does not have an encoding yet, add it \n",
    "            encoding_shuffle_off[var] = comp\n",
    "\n",
    "    for var, comp in compression_shuffle_on.items():  # repeat for encoding_shuffle_on\n",
    "        if var in encoding_shuffle_on:                \n",
    "            encoding_shuffle_on[var].update(comp)\n",
    "        else:                                          \n",
    "            encoding_shuffle_on[var] = comp\n",
    "elif hasattr(ds, 'encoding') and list(encoding.keys())[0] == 'unlimited_dims': # if encoding exists, but not useful, then skip\n",
    "    encoding = ds.encoding  # load the encoding from the dataset\n",
    "    print (f\"Encoding found in dataset starts with 'unlimited dims:', is likely default/not useful. Skipped, instead only using deflate compression. Encoding found: {encoding}\")  # print the encoding to check\n",
    "    encoding_shuffle_off = compression_shuffle_off\n",
    "    encoding_shuffle_on  = compression_shuffle_on\n",
    "else:\n",
    "    print(\"No encoding found in dataset (scaling etc), using only default deflate compression.\")\n",
    "    encoding_shuffle_off = compression_shuffle_off\n",
    "    encoding_shuffle_on  = compression_shuffle_on\n",
    "\n",
    "#print(encoding_shuffle_off)   # print the compression settings to check\n",
    "#print(encoding_shuffle_on)    # print the compression settings to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable p: shuffle on is smaller: 2591 kB < 2680 kB\n",
      "Variable u: shuffle on is LARGER: 44298 kB > 18358 kB\n",
      "Variable v: shuffle on is LARGER: 43944 kB > 17598 kB\n",
      "Variable w: shuffle on is LARGER: 42030 kB > 14908 kB\n",
      "Variable anl1: shuffle on is smaller: 1951 kB < 2238 kB\n",
      "Variable anl2: shuffle on is smaller: 2425 kB < 2767 kB\n",
      "Variable a1: shuffle on is smaller: 2623 kB < 3750 kB\n",
      "Variable a2: shuffle on is smaller: 2781 kB < 3953 kB\n",
      "Variable a3: shuffle on is smaller: 2696 kB < 3841 kB\n",
      "Variable cor1: shuffle on is smaller: 5729 kB < 7924 kB\n",
      "Variable cor2: shuffle on is smaller: 5816 kB < 8028 kB\n",
      "Variable cor3: shuffle on is smaller: 5736 kB < 7951 kB\n",
      "Variable snr1: shuffle on is LARGER: 14228 kB > 5325 kB\n",
      "Variable snr2: shuffle on is LARGER: 14090 kB > 5579 kB\n",
      "Variable snr3: shuffle on is LARGER: 14147 kB > 5419 kB\n",
      "Variable voltage: shuffle on is LARGER: 1444 kB > 658 kB\n",
      "Variable heading: shuffle on is LARGER: 7161 kB > 3672 kB\n",
      "Variable pitch: shuffle on is LARGER: 5651 kB > 2255 kB\n",
      "Variable roll: shuffle on is LARGER: 5490 kB > 2226 kB\n",
      "Variable burst: shuffle on is smaller: 76 kB < 136 kB\n"
     ]
    }
   ],
   "source": [
    "# Now save the dataset with both shuffle settings, 1 variable at a time, compare the file sizes, then use optimal settings\n",
    "\n",
    "# for every variable in the dataset, if the number of elements in the variable is larger than 1000, print the variable name and the number of elements\n",
    "encoding_shuffle_optimal = copy.deepcopy(encoding_shuffle_on)  # make a copy of the encoding dict, to add the shuffle setting\n",
    "\n",
    "for var in ds.data_vars:\n",
    "    if ds[var].size > 1000:\n",
    "        #print(f'Processing variable: {var} with size {ds[var].size}')\n",
    "        \n",
    "        # make a new dataset, containing only the selected variable, dropping all other variables\n",
    "        ds_1var = ds[[var]].copy()  # create a new dataset with only the selected variable\n",
    "\n",
    "        # make a new encoding dictionary, with only variables and coordinates that are in ds_1var\n",
    "        encoding_1var_shuffle_off = {var: encoding_shuffle_off[var] for var in list(ds_1var.data_vars) + list(ds_1var.coords)}\n",
    "        encoding_1var_shuffle_on  = {var: encoding_shuffle_on[var]  for var in list(ds_1var.data_vars) + list(ds_1var.coords)}\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            ds_1var.to_netcdf(os.path.join(folder_in, filename_1var_shuffle_off), encoding=encoding_1var_shuffle_off)\n",
    "        except Exception as e:\n",
    "            if str(e).startswith(\"Cannot cast ufunc 'divide' output from dtype\"):\n",
    "                print(f\"Error for variable {var}: {e}. Casting variable to float64 and retrying.\")\n",
    "                ds_1var[var] = ds_1var[var].astype('float64')\n",
    "                ds_1var.to_netcdf(os.path.join(folder_in, filename_1var_shuffle_off), encoding=encoding_1var_shuffle_off)\n",
    "                ds[var] = ds[var].astype('float64')  # also update the original dataset with the new data type. (order: after saving, so only if it works)\n",
    "            else:\n",
    "                raise\n",
    "                        \n",
    "        #ds_1var.to_netcdf(os.path.join(folder_in, filename_1var_shuffle_off), encoding=encoding_1var_shuffle_off)\n",
    "        ds_1var.to_netcdf(os.path.join(folder_in, filename_1var_shuffle_on),  encoding=encoding_1var_shuffle_on)\n",
    "\n",
    "        # read the file size of the saved files\n",
    "        size_shuffle_off = os.path.getsize(os.path.join(folder_in, filename_1var_shuffle_off))\n",
    "        size_shuffle_on  = os.path.getsize(os.path.join(folder_in, filename_1var_shuffle_on))\n",
    "\n",
    "        # if size_shuffle_off is smaller than size_shuffle_on, update the encoding_shuffle_optimal dictionary for the variable\n",
    "        if size_shuffle_on < size_shuffle_off:\n",
    "            print(f'Variable {var}: shuffle on is smaller: {size_shuffle_on/1024:.0f} kB < {size_shuffle_off/1024:.0f} kB')\n",
    "        else:           \n",
    "            encoding_shuffle_optimal[var] = encoding_shuffle_off[var]\n",
    "            print(f'Variable {var}: shuffle on is larger: {size_shuffle_on/1024:.0f} kB > {size_shuffle_off/1024:.0f} kB')\n",
    "\n",
    "# Save the dataset with the optimal encoding, then remove the temporary nc files\n",
    "#ds.to_netcdf(os.path.join(folder_in, filename_out_shuffle_optimal), encoding=encoding_shuffle_optimal)\n",
    "#os.remove(os.path.join(folder_in, filename_1var_shuffle_off))\n",
    "#os.remove(os.path.join(folder_in, filename_1var_shuffle_on))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d59d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable p: shuffle on is smaller: 2591 kB < 2680 kB\n",
      "Variable u: shuffle on is larger: 44298 kB > 18358 kB\n",
      "Variable v: shuffle on is larger: 43944 kB > 17598 kB\n",
      "Variable w: shuffle on is larger: 42030 kB > 14908 kB\n",
      "Variable anl1: shuffle on is smaller: 1951 kB < 2238 kB\n",
      "Variable anl2: shuffle on is smaller: 2425 kB < 2767 kB\n",
      "Variable a1: shuffle on is smaller: 2623 kB < 3750 kB\n",
      "Variable a2: shuffle on is smaller: 2781 kB < 3953 kB\n",
      "Variable a3: shuffle on is smaller: 2696 kB < 3841 kB\n",
      "Variable cor1: shuffle on is smaller: 5729 kB < 7924 kB\n",
      "Variable cor2: shuffle on is smaller: 5816 kB < 8028 kB\n",
      "Variable cor3: shuffle on is smaller: 5736 kB < 7951 kB\n",
      "Variable snr1: shuffle on is larger: 14228 kB > 5325 kB\n",
      "Variable snr2: shuffle on is larger: 14090 kB > 5579 kB\n",
      "Variable snr3: shuffle on is larger: 14147 kB > 5419 kB\n",
      "Variable voltage: shuffle on is larger: 1444 kB > 658 kB\n",
      "Variable heading: shuffle on is larger: 7161 kB > 3672 kB\n",
      "Variable pitch: shuffle on is larger: 5651 kB > 2255 kB\n",
      "Variable roll: shuffle on is larger: 5490 kB > 2226 kB\n",
      "Variable burst: shuffle on is smaller: 76 kB < 136 kB\n"
     ]
    }
   ],
   "source": [
    "encoding_shuffle_optimal = get_optimal_shuffle_encoding(folder_in, filename_in)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521b16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbc5d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 4GB\n",
      "Dimensions:         (time: 15240, profile_number: 16, echos: 3, obs_number: 720)\n",
      "Dimensions without coordinates: time, profile_number, echos, obs_number\n",
      "Data variables:\n",
      "    time_num        (time) datetime64[ns] 122kB ...\n",
      "    time_string     (time) <U23 1MB ...\n",
      "    file_name       (time) <U42 3MB ...\n",
      "    profile_angle   (profile_number) float32 64B ...\n",
      "    ini_beam_angle  (profile_number) float32 64B ...\n",
      "    radius_lidar    (echos, profile_number, obs_number, time) float32 2GB ...\n",
      "    intensity       (echos, profile_number, obs_number, time) float32 2GB ...\n",
      "Attributes:\n",
      "    name:                   storm1_lidar1_polar polar\n",
      "    summary:                Hybrid Dune campaign, data of lidar 1 during storm 1\n",
      "    instrument:             lidar 1\n",
      "    period:                 storm 1, 2024-12-18 to 2024-12-20\n",
      "    instrument type:        Sick Multiscan 165\n",
      "    time zone:              UTC+1\n",
      "    contact person:         Daan Poppema\n",
      "    emailadres:             d.w.poppema@tudelft.nl\n",
      "    modification datetime:  26-Feb-2025 17:29:24\n",
      "    version:                v1\n",
      "    version comments:       \n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
