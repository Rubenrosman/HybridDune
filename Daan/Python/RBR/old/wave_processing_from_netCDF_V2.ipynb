{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from scipy.signal import welch\n",
    "sys.path.append(r'C:\\Users\\dpoppema\\Documents\\GitHub\\HybridDune\\Ruben\\Pressure_sensors\\S1\\RBR_05') # to find the puv.py file\n",
    "import puv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input data: parameters, instrument names, file locations\n",
    "# Physical constants -----------------------------------------------------------------------------------\n",
    "rho = 1027 #kg/m3, for seawater at 9C, avg temp at HKZ measurement station\n",
    "g = 9.8125  # value Zandmotor\n",
    "\n",
    "# # input parameters per file ----------------------------------\n",
    "subfolder_in_all = ['refP1 RBR4','S1P2 RBR3', 'S1P3 RBR5', 'S2P3 RBR1', 'S3P3 RBR6', 'S4P3 RBR2'] # subfolder where file is sitting within experimentFolder (on O drive Daan)\n",
    "sf_all = [8, 8, 16, 8, 16, 8] #[hz] sampling frequency\n",
    "\n",
    "# # input parameters general ---------------------------------------------\n",
    "experimentFolder = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1'                  # path where the data is sitting # Rubens Laptop\n",
    "instrumentname_all = subfolder_in_all #['refP1 RBR4', 'S3P6 RBR6']\n",
    "\n",
    "# Settings spectral analysis: segments (Welch method) -------------------\n",
    "p_blocks = 20          # number of segments within block, for the Welch method\n",
    "D_length = 1200        # Duration of block in seconds (20 minutes)\n",
    "D_length_s = '1200s'   # Duration of block in seconds (20 minutes). (same as above, but as string for xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "instrument = instrumentname_all[i]  # select instrument\n",
    "instrFile = os.path.join(experimentFolder,'QC', instrument +' p_rel.nc')\n",
    "ncOutFile = os.path.join(experimentFolder,'tailored', instrument +'.nc')\n",
    "\n",
    "# %% load the data from netcdf\n",
    "ds0 = xr.open_dataset(instrFile)   # dataset with relative pressure\n",
    "#print(np.size(ds0.p.values), 'time steps in dataset')\n",
    "\n",
    "# frequency resolution in fourier space --------------------------------------------\n",
    "### delta_f = p_blocks/D_timeframe ###\n",
    "fresolution = p_blocks / D_length # Frequency resolution is 1/T_segment = n_segments / T_block\n",
    "nperseg = D_length * sf_all[i] / p_blocks - 0.5 #dim should be len(ds.f); whelch has (nperseg/2 +1)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# reshape to one column per burst in data array\n",
    "pt = ds0.p_rel.values # relative pressure, pAir subtracted\n",
    "nSamples = len(pt)\n",
    "dt = ds0.isel(t=1).t - ds0.isel(t=0).t\n",
    "\n",
    "burstDuration = pd.Timedelta(D_length_s)  # Burst duration (1200 seconds = 20 minutes)\n",
    "burstLength = int(burstDuration / dt)\n",
    "nBursts = int(np.floor(nSamples / burstLength))\n",
    "\n",
    "pt = pt[:nBursts * burstLength]\n",
    "t_full = ds0.t.values[:nBursts * burstLength]  # time vector for all samples, up to the last complete burst. skip incomplete burst at end\n",
    "t_block = t_full[::burstLength]  # take every nth step, so t = t0 of every burst\n",
    "\n",
    "N = (ds0.t.values[:burstLength] - ds0.t.values[0]) / np.timedelta64(1, 's')  # time in seconds since start of burst\n",
    "\n",
    "# Cast pressure into a 2D array --------------------------\n",
    "ds_2D = xr.Dataset(data_vars={},    # Temporary 2D dataset, with cooridnates t (no. of blocks), N (obs within block)\n",
    "                coords={'t_full': t_full, #ds0.t.values,                 \n",
    "                        't_block': t_block,\n",
    "                        'N': N,\n",
    "                        'f': np.arange(0, ds0.sf.values / 2, fresolution)})\n",
    "\n",
    "ds_2D['p'] = (('t', 'N'), pt.reshape((nBursts, burstLength)))      # relative pressure, pAir subtracted\n",
    "\n",
    "\n",
    "# Filtering ----------------------------------------------------------------------------------------\n",
    "# Remove water height below 30 cm\n",
    "# ds_2D['p'] = ds_2D['p'].where(ds_2D['p'] > 0.3 * (rho * g))\n",
    "\n",
    "# Remove bursts where the standard deviation is too low, indicating the instrument fell dry\n",
    "# ds_2D['p'] = ds_2D['p'].where(ds_2D.p.std(dim='N') > 70)                  # keep when std > 70 Pa, i.e. > 7 mm water height equivalent\n",
    "\n",
    "# make a new dataset that has an extra dimension to accomodate for the frequency axis ----------------------------------\n",
    "ds_out = xr.Dataset(data_vars={},\n",
    "                coords={'t_full': t_full, #ds0.t.values,                 \n",
    "                        't_block': t_block,\n",
    "                        'f': np.arange(0, ds0.sf.values / 2, fresolution)})\n",
    "\n",
    "# # put all variables in this new dataset\n",
    "ds_out.attrs = ds0.attrs\n",
    "for key in ds0.data_vars:\n",
    "    ds_out[key] = ds0[key]\n",
    "\n",
    "# Add metadata, drop raw pressure\n",
    "ds_out['f'].attrs = {'units': 'Hz'}\n",
    "ds_out['p'] = ds_out.p_rel # renaming p_rel to p (overwriting existing p variable)\n",
    "ds_out = ds_out.drop_vars('p_rel') # and  dropping the old p_rel variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp: resize p -----------------------------------------------------\n",
    "\n",
    "# Create a continuous time array\n",
    "# Make full time vector\n",
    "t0 = datetime(2024, 12, 12, 9, 0, 0)\n",
    "t_end = datetime(2024, 12, 27, 16, 20, 0)\n",
    "t_end = datetime(2024, 12, 27, 16, 19, 59, 999999)\n",
    "\n",
    "t_full   = pd.date_range(t0, t_end, freq='{}s'.format(1 / 16)) # 16hz time vector\n",
    "x = np.arange(0, len(t_full))  # create an index for the full time vector;\n",
    "\n",
    "ds_new = xr.Dataset(data_vars={},\n",
    "                coords={'t_full': t_full,\n",
    "                        't': ds0.t.values,\n",
    "                        'N': N,\n",
    "                        'f': np.arange(0, ds0.sf.values / 2, fresolution)})\n",
    "\n",
    "# put all variables in this new dataset\n",
    "for key in ds.data_vars:\n",
    "    ds_new[key] = ds[key]\n",
    "\n",
    "#print(ds_new)\n",
    "\n",
    "# Save with compression\n",
    "ncFilePath1 = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\QC\\copy.nc'\n",
    "ncFilePath2 = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\QC\\copy with t_full index.nc'\n",
    "ncFilePath3 = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\QC\\copy deflate4.nc'\n",
    "ncFilePath4 = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\QC\\copy with t_full deflate4.nc'\n",
    "ncFilePath7 = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\QC\\B7-2 with t_full, deflate4 var_coor.nc'\n",
    "\n",
    "encoding3 = {var: {\"zlib\": True, \"complevel\": 4} for var in ds.data_vars}\n",
    "encoding4 = {var: {\"zlib\": True, \"complevel\": 4} for var in ds_new.data_vars}\n",
    "encoding7 = {var: {\"zlib\": True, \"complevel\": 4} for var in list(ds_new.data_vars) + list(ds_new.coords)}\n",
    "\n",
    "#ds.to_netcdf(    ncFilePath1)\n",
    "#ds_new.to_netcdf(ncFilePath2)\n",
    "#ds.to_netcdf(    ncFilePath3, encoding=encoding3)\n",
    "#ds_new.to_netcdf(ncFilePath4, encoding=encoding4)\n",
    "ds_new.to_netcdf(ncFilePath7, encoding=encoding7)\n",
    "\n",
    "nBursts = 1102\n",
    "burstLength = 19200  # number of samples per burst\n",
    "#ds_new['t_2d'] = (('t', 'N'), x.reshape((nBursts, burstLength)))      # relative pressure, pAir subtracted\n",
    "\n",
    "# reshape variable t_2d to 1d vector, stacking dimension t and N to single dimension t_full\n",
    "ds_new['p_1d'] = ds_new.p.stack(t_full=('t', 'N'))\n",
    "ds_new.p_1d.attrs = ds_new.p.attrs\n",
    "#ds_new.p2.name = 'p2'\n",
    "\n",
    "# remove variable p from dateset ds_net\n",
    "ds_new = ds_new.drop_vars('p')\n",
    "\n",
    "# save reshaped\n",
    "#ncFilePath5 = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\QC\\copy with t_full reshape.nc'\n",
    "ncFilePath6 = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\QC\\copy with t_full reshape deflate4.nc'\n",
    "encoding6 = {var: {\"zlib\": True, \"complevel\": 4} for var in ds_new.data_vars}\n",
    "# ds_new.to_netcdf(ncFilePath5)\n",
    "# ds_new.to_netcdf(ncFilePath6, encoding=encoding6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DAAN: REMOVE FILTERING WITH OWN VERSION !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "def remove_outliers(data, threshold=3):\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    mask = np.abs(data - mean) < threshold * std_dev\n",
    "    # filtered_data = np.where(mask, data, mean + threshold * std_dev * np.sign(data - mean))  # Replace outliers with closest value within threshold\n",
    "    filtered_data = np.where(mask, data, np.nan) # Replace outliers with nan\n",
    "    return filtered_data\n",
    "\n",
    "# Create a lambda function to pass the threshold parameter\n",
    "ufunc = lambda x: remove_outliers(x, threshold=3)\n",
    "\n",
    "# Apply the outlier removal function to the pressure data\n",
    "ds['p'] = xr.apply_ufunc(ufunc, \n",
    "                          ds['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "\n",
    "# Interpolate NaN values in the pressure signal\n",
    "ds['p'] = ds['p'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "\n",
    "ds.p.isel(t=111).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial NaN count: 0\n"
     ]
    }
   ],
   "source": [
    "# Print the initial number of NaN values\n",
    "initial_nan_count = np.sum(np.isnan(ds_2D['p'].values))\n",
    "print(\"Initial NaN count:\", initial_nan_count)\n",
    "\n",
    "# Interpolating NaN values using linear interpolation\n",
    "#ds['p'] = ds['p'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "# Handling any remaining NaN values\n",
    "#ds['p'] = ds['p'].ffill(dim='N').bfill(dim='N')\n",
    "\n",
    "# Print the number of NaN values after interpolation\n",
    "#remaining_nan_count = np.sum(np.isnan(ds['p'].values))\n",
    "#print(\"Remaining NaN count:\", remaining_nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pressure filtering ####\n",
    "ufunc = lambda x: puv.band_pass_filter2(ds0.sf.values, x, fmin=0.004, fmax=1.5)\n",
    "\n",
    "ds_2D['p'] = xr.apply_ufunc(ufunc, \n",
    "                          ds_2D['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "\n",
    "# Compute water depth\n",
    "ds_2D['h'] = (ds_2D['p'] / (rho * g) + (ds0['zi'] - ds0['zb'])).mean(dim='N')  # Mean water depth per burst, based on pressure, sensor height and bed level\n",
    "ds_2D['h'].attrs = {'long_name': 'mean water depth', 'units': '[m]'} # avg per burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dpoppema\\Documents\\GitHub\\HybridDune\\Ruben\\Pressure_sensors\\S1\\RBR_05\\puv.py:351: RuntimeWarning: overflow encountered in cosh\n",
      "  Sw = np.cosh(k*h)/np.cosh(k*elev)\n",
      "C:\\Users\\dpoppema\\Documents\\GitHub\\HybridDune\\Ruben\\Pressure_sensors\\S1\\RBR_05\\puv.py:351: RuntimeWarning: overflow encountered in cosh\n",
      "  Sw = np.cosh(k*h)/np.cosh(k*elev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'zs' ()> Size: 8B\n",
      "array(1.77398555)\n",
      "<xarray.DataArray 'zs' ()> Size: 8B\n",
      "array(2.17398555)\n"
     ]
    }
   ],
   "source": [
    "# TEMPORARY: STUDY IMPORTANCE BED LEVEL\n",
    "#    zRD_bedlevel =zb = -1.229         # m NAP\n",
    "#    zRD_sensor = zi =  -0.704         # m NAP\n",
    "\n",
    "# basis ---------------------------------------------------------------\n",
    "zb_test = -1.23 # m NAP\n",
    "zi_test = -0.7\n",
    "\n",
    "# bed 20cm lower ---------------------------------------------------------------\n",
    "zb_test = -1.43 # m NAP\n",
    "zi_test = -0.9\n",
    "ds_2D['h'] = (ds_2D['p'] / (rho * g) + (zi_test - zb_test)).mean(dim='N')  # Relative to bed level\n",
    "\n",
    "ufunc = lambda x, h: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds0.sf.values, x, h, \n",
    "    zi_test,\n",
    "    zb_test,\n",
    "    rho = rho,\n",
    "    g = g,\n",
    "    removeNoise=False,\n",
    "    detrend=True)\n",
    "fx, h = xr.apply_ufunc(ufunc, \n",
    "                              ds_2D['p'], ds_2D['h'],\n",
    "                              input_core_dims=[['N'], []],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "ds_2D['zs'] = h + zb_test  # water level (surface elevation) = bed level + depth\n",
    "z1 = ds_2D['zs'].isel(t=531)  # select frequency 0.5 Hz, column 133\n",
    "\n",
    "#ufunc = lambda p: welch(p, fs=ds0.sf.values, nperseg=nperseg, detrend='constant', window='hann') # Detrend: is per segment. 1min, about constant, so false used\n",
    "#ds_2D['frequencies'], ds_2D['psd'] = xr.apply_ufunc(ufunc,\n",
    "#                                                ds_2D['zs'],\n",
    "#                                                input_core_dims=[['N']],\n",
    "#                                                output_core_dims=[['f'], ['f']],\n",
    "#                                                vectorize=True)\n",
    "\n",
    "#ufunc = lambda psd: puv.compute_wave_params(ds_2D.f.values, psd, fmin=0.004 , fmax=5)   # DAAN: CHECK: WHY fmax=5? Different result than 1.5?\n",
    "#ds_2D['Hm0'], ds_2D['Tp'], ds_2D['Tm01'], ds_2D['Tm02'], ds_2D['Tmm10'], ds_2D['Tps'] = xr.apply_ufunc(ufunc,\n",
    "#                                                                          ds_2D['psd'],\n",
    "#                                                                          input_core_dims=[['f']],\n",
    "#                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "#                                                                          vectorize=True)\n",
    "\n",
    "# bed 20cm higher ---------------------------------------------------------------\n",
    "zb_test = -1.03 # m NAP\n",
    "zi_test = -0.5\n",
    "\n",
    "ds_2D['h'] = (ds_2D['p'] / (rho * g) + (zi_test - zb_test)).mean(dim='N')  # Relative to bed level\n",
    "\n",
    "ufunc = lambda x, h: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds0.sf.values, x, h, \n",
    "    zi_test,\n",
    "    zb_test,\n",
    "    rho = rho,\n",
    "    g = g,\n",
    "    removeNoise=False,\n",
    "    detrend=True)\n",
    "fx, h = xr.apply_ufunc(ufunc, \n",
    "                              ds_2D['p'], ds_2D['h'],\n",
    "                              input_core_dims=[['N'], []],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "ds_2D['zs'] = h + zb_test  # water level (surface elevation) = bed level + depth\n",
    "z3 = ds_2D['zs'].isel(t=531)  # select frequency 0.5 Hz, column 133\n",
    "\n",
    "# Compare results ----------------------------------------------------\n",
    "print( np.mean(z1))\n",
    "print( np.mean(z3))\n",
    "\n",
    "#print(z1[1])\n",
    "#print(z3[1])\n",
    "#print(ds_2D['Hm0'].isel(t=531))  # select frequency 0.5 Hz, column 133\n",
    "#print(ds_2D['Hm0'].isel(t=531))  # select frequency 0.5 Hz, column 133\n",
    "\n",
    "# plot ds_2D\n",
    "z_dif = z1-z3\n",
    "#z_dif.plot(label='zs at 0.5 Hz')\n",
    "#plt.xlabel('Time')\n",
    "\n",
    "# Conclusion: different bed levels give no difference in z_mean, but difference in z(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several wave statistics computations, only based on pressure, for full bandpass\n",
    "# Threshold= 4    # DAAN: SKIP\n",
    "ufunc = lambda x, h: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds0.sf.values, x, h, \n",
    "    ds0.zi.values,\n",
    "    ds0.zb.values,\n",
    "    rho = rho,\n",
    "    g = g,\n",
    "    removeNoise=False,\n",
    "    detrend=True)\n",
    "\n",
    "fx, h = xr.apply_ufunc(ufunc, \n",
    "                              ds_2D['p'], ds_2D['h'],\n",
    "                              input_core_dims=[['N'], []],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "ds_2D['zs'] = ds0.zb.values + h # water level (surface elevation) = bed level + depth\n",
    "ds_2D['zs'].attrs = {'units': 'm +NAP', 'long_name': 'surface elevation'}   # DAAN: CHECK: MORE METADATA NEEDED?\n",
    "\n",
    "# ufunc = lambda zs: remove_outliers(zs, threshold=Threshold)   # DAAN: SKIP\n",
    "\n",
    "# ds['zs'] = xr.apply_ufunc(ufunc, \n",
    "#                           ds['zs'],\n",
    "#                           input_core_dims=[['N']],\n",
    "#                           output_core_dims=[['N']],\n",
    "#                           vectorize=True)\n",
    "\n",
    "# # Interpolate NaN values in the pressure signal\n",
    "# ds['zs'] = ds['zs'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "# Drop values that are below bed level. \n",
    "# ds['zs'] = ds['zs'].where(ds['zs'] >= 0.0, drop=True)\n",
    "\n",
    "ufunc = lambda p: welch(p, fs=ds0.sf.values, nperseg=nperseg, detrend='constant', window='hann') # Detrend: is per segment. 1min, about constant, so false used\n",
    "\n",
    "ds_2D['frequencies'], ds_2D['psd'] = xr.apply_ufunc(ufunc,\n",
    "                                                ds_2D['zs'],\n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[['f'], ['f']],\n",
    "                                                vectorize=True)\n",
    "\n",
    "ufunc = lambda psd: puv.compute_wave_params(ds_2D.f.values, psd, fmin=0.004 , fmax=5)   # DAAN: CHECK: WHY fmax=5? Different result than 1.5?\n",
    "\n",
    "ds_2D['Hm0'], ds_2D['Tp'], ds_2D['Tm01'], ds_2D['Tm02'], ds_2D['Tmm10'], ds_2D['Tps'] = xr.apply_ufunc(ufunc,\n",
    "                                                                          ds_2D['psd'],\n",
    "                                                                          input_core_dims=[['f']],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(438, 9600)\n",
      "(438, 1)\n",
      "(438, 19200)\n",
      "<xarray.DataArray 'h' (t: 438)> Size: 4kB\n",
      "array([0.67325847, 0.64387871, 0.60886407, 0.59656408, 0.6284327 ,\n",
      "       0.66613148, 0.75689849, 0.8656114 , 0.98823653, 1.19220973,\n",
      "       1.47550996, 1.8574465 , 2.21934196, 2.45503898, 2.5695246 ,\n",
      "       2.57193093, 2.48148932, 2.40052476, 2.31656315, 2.24155846,\n",
      "       2.12814885, 2.01761469, 1.88810426, 1.70769759, 1.49474718,\n",
      "       1.31695377, 1.14076224, 0.97109879, 0.82766111, 0.77615699,\n",
      "       0.73318488, 0.74938464, 0.75396073, 0.75989304, 0.72319393,\n",
      "       0.64644241, 0.60209574, 0.55251325, 0.50580988, 0.48284198,\n",
      "       0.46240305, 0.43320333, 0.43474024, 0.4337127 , 0.503797  ,\n",
      "       0.54254058, 0.66374661, 0.83511156, 1.11252689, 1.47528213,\n",
      "       1.75998795, 1.95991412, 2.01778279, 1.96411902, 1.87134399,\n",
      "       1.77130097, 1.6633274 , 1.52970974, 1.38804032, 1.23956063,\n",
      "       1.05435012, 0.87797699, 0.72447308, 0.56461696, 0.44915381,\n",
      "       0.3674024 , 0.33565933, 0.34259458, 0.3804389 , 0.39189963,\n",
      "       0.4608416 , 0.4615424 , 0.44391179, 0.37078603, 0.3186567 ,\n",
      "       0.2945602 , 0.28252558, 0.28156904, 0.28890695, 0.32022837,\n",
      "       0.45116797, 0.6390271 , 0.98045482, 1.34738281, 1.71370337,\n",
      "       2.03280698, 2.29967143, 2.43284391, 2.48713001, 2.43205181,\n",
      "       2.35922509, 2.2897408 , 2.219227  , 2.16545936, 2.11951124,\n",
      "       2.05350896, 1.97176293, 1.86827889, 1.76120843, 1.63887246,\n",
      "...\n",
      "       1.72086634, 1.86203057, 1.95993953, 2.15857485, 2.31788897,\n",
      "       2.49611364, 2.68132989, 2.87644572, 2.96481287, 2.94689479,\n",
      "       3.00775304, 2.90794165, 2.79093684, 2.84781556, 2.78931345,\n",
      "       2.7008398 , 2.57604134, 2.51181149, 2.42168378, 2.25159071,\n",
      "       2.12278489, 2.01423784, 1.96339243, 1.8606609 , 1.83057745,\n",
      "       1.82587787, 1.76028141, 1.70832237, 1.66233741, 1.59723494,\n",
      "       1.57080263, 1.52004253, 1.43763854, 1.45113347, 1.46365434,\n",
      "       1.50201433, 1.57198659, 1.61864517, 1.73132274, 1.83350922,\n",
      "       1.97462669, 2.21433496, 2.39725321, 2.55751028, 2.68045137,\n",
      "       2.71629645, 2.69121875, 2.70430756, 2.70272873, 2.65082301,\n",
      "       2.45868746, 2.31805014, 2.39181964, 2.59377222, 2.59307161,\n",
      "       2.57222767, 2.50071968, 2.31582422, 2.13999967, 1.92130389,\n",
      "       1.8821778 , 1.8937812 , 1.94029815, 1.74673293, 1.78819186,\n",
      "       1.76238481, 1.80974346, 1.80379862, 1.80787241, 1.8981761 ,\n",
      "       1.91001085, 1.82424031, 1.89719651, 1.8678452 , 1.94532071,\n",
      "       1.96479973, 2.0012165 , 2.10516537, 2.15660118, 2.06812496,\n",
      "       2.21397722, 2.25178936, 2.35929326, 2.30677765, 2.32332941,\n",
      "       2.34058228, 2.26376337, 2.11728254, 2.11773104, 1.97047825,\n",
      "       1.8781279 , 1.69481594, 1.53558094, 1.35288697, 1.21042048,\n",
      "       1.05563978, 0.92808212, 0.78076163])\n",
      "Dimensions without coordinates: t\n"
     ]
    }
   ],
   "source": [
    "# # TIME-VARYING BEDLEVEL --------------------------------------------------------\n",
    "# Define z_bed_obs and t_bed_obs for RBR6 -----------------\n",
    "t_bed_obs = pd.to_datetime(['2024-12-17 10:30',\n",
    "                            '2024-12-20 12:20',\n",
    "                            '2024-12-23 12:00'])\n",
    "t_block2 = pd.to_datetime(t_block)  # Convert to pandas datetime for consistency\n",
    "\n",
    "z_bed_obs = np.array([-1.229, -1.103, -0.964] )  # TEMP EXAMPLE\n",
    "\n",
    "# Interpolate z_bed_obs to z_bed_block for time t_block\n",
    "z_bed_block = np.interp(t_block2, t_bed_obs, z_bed_obs)  # Interpolate bed level to block time vector\n",
    "z_bed_block2 = np.reshape(z_bed_block,(len(z_bed_block),1)) # reshape to column vector for compatibility with p\n",
    "z_bed_block3 = z_bed_block2.repeat(19200,axis=1)\n",
    "\n",
    "# Calculate effect time-varying bedlevel on water depth ----------------------------------------\n",
    "print(np.shape(ds_2D['p']))\n",
    "print(np.shape(z_bed_block2))\n",
    "print(np.shape(z_bed_block3))\n",
    "\n",
    "#print(np.shape(ds_2D['z_bed_block']))\n",
    "ds_2D['h'] = ( (ds_2D['p'] / rho / g) + ds0['zi'] - z_bed_block2 ).mean(dim='N') # Mean water depth per burst: h=p/rho/g + (z_i-z_b)\n",
    "\n",
    "ufunc = lambda x, h, zb: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds0.sf.values, x, h, \n",
    "    ds0.zi.values,\n",
    "    zb, \n",
    "    rho = rho,\n",
    "    g = g,\n",
    "    removeNoise=False,\n",
    "    detrend=True)\n",
    "\n",
    "fx, h = xr.apply_ufunc(ufunc, \n",
    "                              ds_2D['p'], ds_2D['h'], z_bed_block,\n",
    "                              input_core_dims=[['N'], [],[]],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "ds_2D['zs'] = z_bed_block2 + h # water level (surface elevation) = bed level + depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## low frequencies: IG waves ##\n",
    "## now first filter bandpass, then compute wave_params\n",
    "\n",
    "ufunc = lambda x: puv.band_pass_filter2(ds.sf.values, x, fmin=0.004, fmax=0.05)\n",
    "\n",
    "ds['p_low'] = xr.apply_ufunc(ufunc, \n",
    "                          ds['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "\n",
    "ufunc = lambda x, h: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds.sf.values, x, h, \n",
    "    ds.zi.values,\n",
    "    ds.zb.values,\n",
    "    rho=1027,\n",
    "    g=9.8125,\n",
    "    removeNoise=False,\n",
    "    detrend=True)\n",
    "\n",
    "fx, ds['zs_low'] = xr.apply_ufunc(ufunc, \n",
    "                              ds['p_low'], ds['h'],\n",
    "                              input_core_dims=[['N'], []],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "\n",
    "# ufunc = lambda zs: remove_outliers(zs, threshold=Threshold)\n",
    "\n",
    "# ds['zs_low'] = xr.apply_ufunc(ufunc, \n",
    "#                           ds['zs_low'],\n",
    "#                           input_core_dims=[['N']],\n",
    "#                           output_core_dims=[['N']],\n",
    "#                           vectorize=True)\n",
    "\n",
    "# ds['zs_low'] = ds['zs_low'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "# ds['zs_low'] = ds['zs_low'].where(ds['zs_low'] >= 0.0, drop=True)\n",
    "\n",
    "ds['zs_low'].attrs = {'units': 'm', 'long_name': 'surface elevation low freq.'}\n",
    "\n",
    "\n",
    "ufunc = lambda p: welch(p, fs=ds.sf.values, nperseg=nperseg, detrend='constant', window='hann')\n",
    "\n",
    "ds['frequencies_low'], ds['psd_low'] = xr.apply_ufunc(ufunc,\n",
    "                                                ds['zs_low'],\n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[['f'], ['f']],\n",
    "                                                vectorize=True)\n",
    "\n",
    "ufunc = lambda psd: puv.compute_wave_params(ds.f.values, psd, fmin=0.004 , fmax=0.05)\n",
    "\n",
    "ds['Hm0_low'], ds['Tp_low'], ds['Tm01_low'], ds['Tm02_low'], ds['Tmm10_low'], ds['Tps_low'] = xr.apply_ufunc(ufunc,\n",
    "                                                                          ds['psd_low'],\n",
    "                                                                          input_core_dims=[['f']],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## High frequencies: wind-waves ##\n",
    "## now first filter bandpass, then compute wave_params\n",
    "\n",
    "ufunc = lambda x: puv.band_pass_filter2(ds.sf.values, x, fmin=0.05, fmax=5)\n",
    "\n",
    "ds['p_high'] = xr.apply_ufunc(ufunc, \n",
    "                          ds['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "\n",
    "ufunc = lambda x, h: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds.sf.values, x, h, \n",
    "    ds.zi.values,\n",
    "    ds.zb.values,\n",
    "    rho=1027,\n",
    "    g=9.8125,\n",
    "    removeNoise=False,\n",
    "    detrend=True)\n",
    "\n",
    "t, ds['zs_high'] = xr.apply_ufunc(ufunc, \n",
    "                              ds['p_high'], ds['h'],\n",
    "                              input_core_dims=[['N'], []],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "\n",
    "ufunc = lambda zs: remove_outliers(zs, threshold=Threshold)\n",
    "\n",
    "# ds['zs_high'] = xr.apply_ufunc(ufunc, \n",
    "#                           ds['zs_high'],\n",
    "#                           input_core_dims=[['N']],\n",
    "#                           output_core_dims=[['N']],\n",
    "#                           vectorize=True)\n",
    "\n",
    "# ds['zs_high'] = ds['zs_high'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "# ds['zs_high'] = ds['zs_high'].where(ds['zs_high'] >= 0.0, drop=True)\n",
    "\n",
    "ds['zs_high'].attrs = {'units': 'm', 'long_name': 'surface elevation high freq.'}\n",
    "\n",
    "\n",
    "\n",
    "ufunc = lambda p: welch(p, fs=ds.sf.values, nperseg=nperseg, detrend='constant', window='hann')\n",
    "\n",
    "ds['frequencies_high'], ds['psd_high'] = xr.apply_ufunc(ufunc,\n",
    "                                                ds['zs_high'],\n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[['f'], ['f']],\n",
    "                                                vectorize=True)\n",
    "\n",
    "ufunc = lambda psd: puv.compute_wave_params(ds.f.values, psd, fmin=0.05 , fmax=5)\n",
    "\n",
    "ds['Hm0_high'], ds['Tp_high'], ds['Tm01_high'], ds['Tm02_high'], ds['Tmm10_high'], ds['Tps_high'] = xr.apply_ufunc(ufunc,\n",
    "                                                                          ds['psd_high'],\n",
    "                                                                          input_core_dims=[['f']],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## skewness of waves ##\n",
    "ufunc = lambda p: puv.compute_SkAs(ds.sf.values,p,fpfac =None, fbounds = None)   \n",
    "\n",
    "ds['Sk'], ds['As'], ds['sig'] =  xr.apply_ufunc(ufunc,\n",
    "                                                ds['p'], \n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[[], [], []],\n",
    "                                                vectorize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all variables with dimension 'N'\n",
    "# for var in ds.data_vars:\n",
    "#     if 'N' in ds[var].dims:\n",
    "#         ds[var] = ds[var].stack(t_N=('t', 'N'))\n",
    "\n",
    "# %% write to file\n",
    "# we strip all information on burst scale from the dataset to reduce size (and this info is already present in the raw_netcdf version of the data)\n",
    "# dsTailored = ds.drop_dims('N')\n",
    "dsTailored = ds\n",
    "\n",
    "\n",
    "if not os.path.isdir(os.path.join(experimentFolder,'tailored')):\n",
    "    os.mkdir(os.path.join(experimentFolder,'tailored'))\n",
    "ncFilePath = os.path.join(experimentFolder, 'tailored', ds0.instrument + '.nc')\n",
    "dsTailored.to_netcdf(ncFilePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with compression\n",
    "ncFilePath = os.path.join(experimentFolder, 'tailored', ds0.instrument + 'deflate4.nc')\n",
    "encoding = {var: {\"zlib\": True, \"complevel\": 6} for var in dsTailored.data_vars}\n",
    "dsTailored.to_netcdf(ncFilePath, encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape XArray ds\n",
    "\n",
    "# Make full time vector\n",
    "t0 = datetime(2024, 12, 12, 9, 0, 0)\n",
    "t_end = datetime(2024, 12, 27, 16, 20, 0)\n",
    "t_full   = pd.date_range(t0, t_end, freq='{}s'.format(1 / 16)) # 16hz time vector\n",
    "\n",
    "# Add t_full to dsTailered as additional dimension\n",
    "dsTailored = dsTailored.assign_coords(t_full=t_full)\n",
    "dsTailored = dsTailored.expand_dims('t_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continuous time array\n",
    "t_continuous = np.array([t + np.timedelta64(int(n), 's') for t in ds.t.values for n in ds.N.values])\n",
    "\n",
    "# Flatten the burst structure for plotting\n",
    "zs_flat = ds.zs.values.flatten()\n",
    "zs_low_flat = ds.zs_low.values.flatten()\n",
    "zs_high_flat = ds.zs_high.values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.plot(t_continuous, zs_flat, label='zs', alpha=0.7, linewidth=0.9)\n",
    "plt.plot(t_continuous, zs_high_flat, label='zs_high', alpha=0.7, linewidth=0.9)\n",
    "plt.plot(t_continuous, zs_low_flat, label='zs_low', alpha=0.7, linewidth=0.9)\n",
    "\n",
    "ds.h.plot(label='Waterlevel')\n",
    "\n",
    "\n",
    "\n",
    "# give values below y=0 a different color\n",
    "# plt.fill_between(t_continuous, zs_flat, 0, where=zs_flat < 0, color='grey', alpha=1, zorder=4, linewidth=1.5)\n",
    "# plt.fill_between(t_continuous, zs_low_flat, 0, where=zs_low_flat < 0, color='grey', alpha=1, zorder=4, linewidth=1.5)\n",
    "# plt.fill_between(t_continuous, zs_high_flat, 0, where=zs_high_flat < 0, color='grey', alpha=1, zorder=4, linewidth=1.5)\n",
    "plt.axhline(y=0, color='k', linestyle='--', label='Bed level')\n",
    "\n",
    "# Set x-axis limits using specific date stamps\n",
    "start_time = pd.Timestamp(\"2024-12-18T12:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-21T00:00:00\")\n",
    "# plt.xlim(start_time, end_time)\n",
    "\n",
    "plt.axhline((ds.zi-ds.zb).values, color='k', linestyle='--', label='Instrument height above bed')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Surface Elevation (m)')\n",
    "plt.title('Surface Elevation vs Time RBR06 2024-12-16 to 2024-12-27')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hmo \n",
    "plt.figure(figsize=(15, 8))\n",
    "ds.Hm0.plot(label='Hm0')\n",
    "ds.Hm0_low.plot(label=f'Hm0_low (mean={ds.Hm0_low.mean().values:.3g} m)')\n",
    "\n",
    "ds.Hm0_high.plot(label='Hm0_high')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Hm0 (m)')\n",
    "plt.title('Hm0 vs Time')\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis limits using specific date stamps\n",
    "start_time = pd.Timestamp(\"2024-12-18T12:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-21T00:00:00\")\n",
    "# plt.xlim(start_time, end_time)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hs and h\n",
    "plt.figure(figsize=(16, 3))\n",
    "ds.h.plot(label='Waterlevel')\n",
    "# (ds.h + ds.zb).plot(label='Waterlevel + zb (NAP)')\n",
    "\n",
    "# Interpolate between points\n",
    "ds.Hm0.plot(label=f'Hm0 (mean={ds.Hm0.mean().values:.3g} m)')\n",
    "ds.Hm0_low.plot(label=f'Hm0_low (mean={ds.Hm0_low.mean().values:.3g} m)')\n",
    "\n",
    "# ds.Hm0_high.plot(label='Hm0_high')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('(m)')\n",
    "plt.title('Hm0 vs Time')\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis limits using specific date stamps\n",
    "start_time = pd.Timestamp(\"2024-12-21T16:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-23T13:00:00\")\n",
    "# plt.xlim(start_time, end_time)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 111\n",
    "end =120\n",
    "\n",
    "plt.figure(figsize=(16, 2))\n",
    "(ds.zs.isel(t=t)-ds.zs.isel(t=t).mean()).plot(label = f'Water elevation; Hm0: {ds.Hm0.isel(t=t).values:.3g}m')\n",
    "# (ds.zs.isel(t=t)-ds.h.isel(t=t).mean()).plot(label = f'Water elevation; Hm0: {ds.Hm0.isel(t=t).values:.3g}m')\n",
    "plt.grid()\n",
    "plt.xlim(0,end)\n",
    "plt.ylabel(f'\\u03B7 [m]')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.figure(figsize=(16, 2))\n",
    "ds.zs.isel(t=t).plot(color='grey', label= 'total elevation')\n",
    "ds.zs_low.isel(t=t).plot(color='green', label = f'infragravity waves; Hm0: {ds.Hm0_low.isel(t=t).values:.3g}m')\n",
    "plt.grid()\n",
    "plt.xlim(0,end)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.figure(figsize=(16, 2))\n",
    "ds.zs.isel(t=t).plot(color='grey', label= 'total elevation')\n",
    "ds.zs_high.isel(t=t).plot(color='red', label = f'wind waves; Hm0: {ds.Hm0_high.isel(t=t).values:.3g}m')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim(0,end)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to remove outliers\n",
    "# def remove_outliers(data, threshold=3):\n",
    "#     mean = np.mean(data)\n",
    "#     std_dev = np.std(data)\n",
    "#     filtered_data = [x if abs(x - mean) < threshold * std_dev else mean for x in data]\n",
    "#     return np.array(filtered_data)\n",
    "\n",
    "def remove_outliers(data, threshold=3):\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    mask = np.abs(data - mean) < threshold * std_dev\n",
    "    # filtered_data = np.where(mask, data, mean + threshold * std_dev * np.sign(data - mean))  # Replace outliers with closest value within threshold\n",
    "    filtered_data = np.where(mask, data, np.nan) # Replace outliers with nan\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "data = ds.zs.isel(t=t).values  # Extract the data values for the selected time index t\n",
    "\n",
    "# Remove outliers from the data\n",
    "cleaned_data = remove_outliers(data)\n",
    "\n",
    "# Interpolate NaN values in the pressure signal\n",
    "# cleaned_data = cleaned_data.interpolate_na(method='linear')\n",
    "\n",
    "# Calculate the mean of the cleaned data\n",
    "mean_cleaned_data = np.mean(cleaned_data)\n",
    "\n",
    "# Plotting the cleaned data\n",
    "plt.figure(figsize=(16, 2))\n",
    "plt.plot(ds.N, cleaned_data - mean_cleaned_data, label=f'Water elevation; Hm0: {ds.Hm0.isel(t=t).values:.3g}m')\n",
    "plt.grid()\n",
    "plt.xlim(0, 200)\n",
    "plt.ylabel(f'\\u03B7 [m]')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "print(len(cleaned_data)/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "t=111\n",
    "freq = ds.frequencies.isel(t=t)\n",
    "psd = ds.psd.isel(t=t)\n",
    "\n",
    "\n",
    "# Calculate confidence intervals\n",
    "nBlocks = len(ds.zs.isel(t=t)) // nperseg  # Estimate the number of blocks used by Welch's method\n",
    "edf = round(nBlocks * 2)     # Degrees of freedom (approximately 2 per segment)\n",
    "alpha = 0.1                  # 90% confidence level\n",
    "\n",
    "confLow = edf / chi2.ppf(1 - alpha / 2, edf)  # Lower confidence limit\n",
    "confUpper = edf / chi2.ppf(alpha / 2, edf)    # Upper confidence limit\n",
    "\n",
    "# Confidence interval bounds for PSD\n",
    "psd_lower = psd * confLow\n",
    "psd_upper = psd * confUpper\n",
    "\n",
    "\n",
    "\n",
    "### background plot \n",
    "freq_bg, psd_bg = welch(ds.zs.isel(t=t).values, fs=16, nperseg=19200, detrend='constant', window='hann')\n",
    "nBlocks_bg = len(ds.zs.isel(t=t).values) // 19200  # Estimate the number of blocks used by Welch's method\n",
    "edf_bg = round(nBlocks * 2)     # Degrees of freedom (approximately 2 per segment)\n",
    "confLow_bg = edf / chi2.ppf(1 - alpha / 2, edf)  # Lower confidence limit\n",
    "confUpper_bg = edf / chi2.ppf(alpha / 2, edf)    # Upper confidence limit\n",
    "psd_lower_bg = psd_bg * confLow_bg\n",
    "psd_upper_bg = psd_bg * confUpper_bg\n",
    "# plt.plot(freq_bg, psd_upper_bg, color='gray', linestyle= '--')\n",
    "plt.fill_between(freq_bg, psd_lower_bg, psd_upper_bg, color='gray', alpha=0.3, label='Raw spectrum', linestyle='--')\n",
    "\n",
    "### plotting\n",
    "plt.fill_between(freq, psd_lower, psd_upper, color='black', alpha=0.3, label='90% Confidence Interval')\n",
    "plt.semilogy(freq, psd, label='Power Density Spectrum')\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD (mÂ²/Hz)')\n",
    "plt.title(f'Power Spectral Density using Welch\\'s Method for t ={t}')\n",
    "plt.grid()\n",
    "plt.yscale('linear')\n",
    "# plt.xscale('log')\n",
    "plt.xscale('linear')\n",
    "plt.xlim(0,0.6)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_time_index(ds, specific_time):\n",
    "    \"\"\"\n",
    "    Function to find the index 't' for a specific time in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    ds (xarray.Dataset): The dataset containing the time dimension.\n",
    "    specific_time (str or datetime): The specific time to find the index for.\n",
    "    \n",
    "    Returns:\n",
    "    int: The index corresponding to the specific time.\n",
    "    \"\"\"\n",
    "    specific_time = np.datetime64(specific_time)\n",
    "    time_index = np.where(ds.t.values == specific_time)[0]\n",
    "    \n",
    "    if len(time_index) == 0:\n",
    "        raise ValueError(f\"Time {specific_time} not found in the dataset.\")\n",
    "    \n",
    "    return time_index[0]\n",
    "\n",
    "# Example usage\n",
    "specific_time = \"2024-12-20T12:00:00\"\n",
    "t_index = find_time_index(ds, specific_time)\n",
    "print(f\"The index for the specific time {specific_time} is {t_index}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
