{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from scipy.signal import welch\n",
    "sys.path.append(r'C:\\Users\\dpoppema\\Documents\\GitHub\\HybridDune\\Ruben\\Pressure_sensors\\S1\\RBR_05') # to find the puv.py file\n",
    "import puv \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input data: parameters, instrument names, file locations\n",
    "# Physical constants -----------------------------------------------------------------------------------\n",
    "rho = 1027 #kg/m3, for seawater at 9C, avg temp at HKZ measurement station\n",
    "g = 9.8125  # value Zandmotor\n",
    "\n",
    "# # input parameters per file ----------------------------------\n",
    "subfolder_in_all = ['refP1 RBR3', 'S3P3 RBR6', 'S1P2 RBR2', 'S3P2 RBR4', 'S4P2 RBR1','S3P1 RBR5'] # subfolder where file is sitting within experimentFolder (on O drive Daan)\n",
    "\n",
    "# # input parameters general ---------------------------------------------\n",
    "experimentFolder = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series2'                  # path where the data is sitting # Rubens Laptop\n",
    "instrumentname_all = subfolder_in_all #['refP1 RBR4', 'S3P6 RBR6']\n",
    "\n",
    "# Settings spectral analysis: segments (Welch method) -------------------\n",
    "p_blocks = 20          # number of segments within block, for the Welch method\n",
    "D_length = 1200        # Duration of block in seconds (20 minutes)\n",
    "D_length_s = '1200s'   # Duration of block in seconds (20 minutes). (same as above, but as string for xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "instrument = instrumentname_all[i]  # select instrument\n",
    "instrFile = os.path.join(experimentFolder,'QC', instrument +' p_rel - period 2.nc')\n",
    "\n",
    "# %% load the data from netcdf\n",
    "ds0 = xr.open_dataset(instrFile)   # dataset with relative pressure\n",
    "\n",
    "# frequency resolution in fourier space --------------------------------------------\n",
    "### delta_f = p_blocks/D_timeframe ###\n",
    "fresolution = p_blocks / D_length # Frequency resolution is 1/T_segment = n_segments / T_block\n",
    "nperseg = D_length * ds0.sf.values / p_blocks - 0.5 #dim should be len(ds.f); whelch has (nperseg/2 +1)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# reshape to one column per burst in data array\n",
    "pt = ds0.p_rel.values # relative pressure, pAir subtracted\n",
    "nSamples = len(pt)\n",
    "dt = ds0.isel(t=1).t - ds0.isel(t=0).t\n",
    "\n",
    "burstDuration = pd.Timedelta(D_length_s)  # Burst duration (1200 seconds = 20 minutes)\n",
    "burstLength = int(burstDuration / dt)\n",
    "nBursts = int(np.floor(nSamples / burstLength))\n",
    "\n",
    "pt = pt[:nBursts * burstLength]\n",
    "t_full = ds0.t.values[:nBursts * burstLength]  # time vector for all samples, up to the last complete burst. skip incomplete burst at end\n",
    "t_block = t_full[::burstLength]  # take every nth step, so t = t0 of every burst\n",
    "\n",
    "N = (ds0.t.values[:burstLength] - ds0.t.values[0]) / np.timedelta64(1, 's')  # time in seconds since start of burst\n",
    "\n",
    "# Cast pressure into a 2D array --------------------------\n",
    "ds_2D = xr.Dataset(data_vars={},    # Temporary 2D dataset, with cooridnates t (no. of blocks), N (obs within block)\n",
    "                coords={'t_full': t_full, #ds0.t.values,                 \n",
    "                        't_block': t_block,\n",
    "                        'N': N,\n",
    "                        'f': np.arange(0, ds0.sf.values / 2, fresolution)})\n",
    "\n",
    "ds_2D['p'] = (('t_block', 'N'), pt.reshape((nBursts, burstLength)))      # relative pressure, pAir subtracted\n",
    "\n",
    "\n",
    "# Filtering ----------------------------------------------------------------------------------------\n",
    "# Remove water height below 30 cm\n",
    "# ds_2D['p'] = ds_2D['p'].where(ds_2D['p'] > 0.3 * (rho * g))\n",
    "\n",
    "# Remove bursts where the standard deviation is too low, indicating the instrument fell dry\n",
    "# ds_2D['p'] = ds_2D['p'].where(ds_2D.p.std(dim='N') > 70)                  # keep when std > 70 Pa, i.e. > 7 mm water height equivalent\n",
    "\n",
    "# make a new dataset that has an extra dimension to accomodate for the frequency axis ----------------------------------\n",
    "ds_out = xr.Dataset(data_vars={},\n",
    "                coords={'t_full': t_full, #ds0.t.values,                 \n",
    "                        't_block': t_block,\n",
    "                        'f': np.arange(0, ds0.sf.values / 2, fresolution)})\n",
    "ds_out['t_full'].attrs = {'long name': 'time, of every observation'}\n",
    "ds_out['t_block'].attrs = {'long name': 'time of the start of every block (used for calculating wave statistics)'}\n",
    "ds_out['f'].attrs = {'units': 'Hz', 'long name': 'frequency'}\n",
    "\n",
    "# Make copy of ds0, with only complete blocks (i.e., 41 minutes data, 20min blocks, than take first 40 min)\n",
    "ds0 = ds0.sel(t=slice(t_full[-1]))\n",
    "\n",
    "# # put all variables in this new dataset\n",
    "ds_out.attrs = ds0.attrs\n",
    "for key in ds0.data_vars:\n",
    "    ds_out[key] = ds0[key]\n",
    "ds_out.attrs['comment_2'] = ds_out.attrs['comment_1'] # Made with XArray\n",
    "ds_out.attrs['comment_1'] = 'subscripts IG and WW in variable names refer to wave statistiscs of infragravity waves (f<0.05 Hz) or wind waves (f=0.05-1.5 Hz)'\n",
    "\n",
    "# Drop raw pressure, rename p_rel to p\n",
    "ds_out['p'] = ('t_full',ds_out.p_rel.data) # renaming p_rel to p (overwriting existing p variable)\n",
    "ds_out['p'].attrs = ds0['p_rel'].attrs     # copying metadata\n",
    "ds_out = ds_out.drop_vars('p_rel') # and  dropping the old p_rel variable\n",
    "ds_out = ds_out.drop_dims('t') # plus dropping dimension t (now renamed to t_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.0\n"
     ]
    }
   ],
   "source": [
    "print(ds0.p_rel.values[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute (block-averaged) water depth ------------------------------------------------\n",
    "# ### pressure: bandpass filtering  ####\n",
    "ufunc_bandpass    = lambda x: puv.band_pass_filter2(ds0.sf.values, x, fmin=0.004, fmax=1.5)\n",
    "ufunc_bandpass_IG = lambda x: puv.band_pass_filter2(ds0.sf.values, x, fmin=0.004, fmax=0.05)\n",
    "ufunc_bandpass_WW = lambda x: puv.band_pass_filter2(ds0.sf.values, x, fmin=0.05, fmax=1.5)\n",
    "\n",
    "ds_2D['p'] = xr.apply_ufunc(ufunc_bandpass, \n",
    "                          ds_2D['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "ds_2D['p_IG'] = xr.apply_ufunc(ufunc_bandpass_IG, \n",
    "                          ds_2D['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "ds_2D['p_WW'] = xr.apply_ufunc(ufunc_bandpass_WW, \n",
    "                          ds_2D['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "\n",
    "# # TIME-VARYING BEDLEVEL AND INSTRUMENTLEVEL --------------------------------------------------------\n",
    "# Define z_bed_obs and t_bed_obs for RBR6 -----------------\n",
    "t_zb_obs = pd.to_datetime(ds0.t_zb.values)\n",
    "t_block2 = pd.to_datetime(t_block)  # Convert to pandas datetime for consistency\n",
    "zb_obs = ds0.zb.values\n",
    "\n",
    "# Interpolate z_bed_obs to z_bed_block for time t_block\n",
    "zb_block = np.interp(t_block2, t_zb_obs, zb_obs)            # Interpolate bed level to block time vector\n",
    "zb_block2 = np.reshape(zb_block,(len(zb_block),1))          # reshape from row to column vector for compatibility with p\n",
    "\n",
    "# repeat for z_i. Only for file no. 3 (RBR4), the rest had constant bed level, so simply repeat bedlevel there\n",
    "if i == 3: # If file 3 (RBR4): instrument was moved, time-varying zi\n",
    "    t_zi_obs = pd.to_datetime(ds0.t_zi.values)\n",
    "    zi_obs = ds0.zi.values\n",
    "\n",
    "    # 'Interpolate' zi to t_block: use previous known value (so step-wise, not linear interpolation)\n",
    "    idx = np.searchsorted(t_zi_obs, t_block2, side='right') - 1\n",
    "    idx = np.clip(idx, 0, len(zi_obs) - 1)                  # Ensure indices are within bounds\n",
    "    zi_block = zi_obs[idx]\n",
    "    zi_block2 = np.reshape(zi_block, (len(zi_block), 1))    # reshape from row to column vector for compatibility with p\n",
    "else: # if zi did not vary during test, simply repeat zi\n",
    "    zi_block = np.repeat(ds0.zi.values, len(zb_block))\n",
    "    zi_block2 = np.reshape(zi_block, (len(zi_block), 1))    # reshape from row to column vector for compatibility with p\n",
    "\n",
    "# Filter pressure for negative pressures (filter 1), then calculate water depth\n",
    "block_mask = ds_2D['p'] < 0\n",
    "ds_2D['p'] = ds_2D['p'].where(~block_mask, 0)\n",
    "\n",
    "# Compute water depth\n",
    "ds_2D['h_mean'] = ( (ds_2D['p'] / rho / g) + zi_block2 - zb_block2 ).mean(dim='N') # Mean water depth per burst: h=p/rho/g + (z_i-z_b)\n",
    "ds_out['h_mean'] = ds_2D['h_mean']\n",
    "ds_out['h_mean'].attrs = {'long_name': 'mean water depth', 'units': '[m]'} # avg per burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40.28768228 37.2962246  35.84410453 ... 53.87867657 51.08481838\n",
      " 46.60844546]\n"
     ]
    }
   ],
   "source": [
    "print(ds_2D.p.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dpoppema\\AppData\\Local\\anaconda3\\envs\\lidar\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2656: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  output[index] = result\n"
     ]
    }
   ],
   "source": [
    "# Compute wave statistics, for full bandpass, infragrafity waves and wind waves  ------------------------------------------------------------------------------\n",
    "# Attenuate signal: from pressure to surface elevation -------------------------------------\n",
    "ufunc_attenuate = lambda x, h, zi, zb: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds0.sf.values, x, h, \n",
    "    zi,\n",
    "    zb, \n",
    "    rho = rho,\n",
    "    g = g,\n",
    "    removeNoise=False,\n",
    "    detrend=True)\n",
    "\n",
    "fx, h = xr.apply_ufunc(ufunc_attenuate,                                     # attenuate signal (calculate water surface), using p(t), and h_mean and zb_mean (each 1 value per block)\n",
    "                              ds_2D['p'], ds_2D['h'], zi_block, zb_block,\n",
    "                              input_core_dims=[['N'], [],[],[]],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "fx, h_IG = xr.apply_ufunc(ufunc_attenuate,                                     # repeat for infragrafity waves\n",
    "                              ds_2D['p_IG'], ds_2D['h'], zi_block, zb_block,\n",
    "                              input_core_dims=[['N'], [],[],[]],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "fx, h_WW = xr.apply_ufunc(ufunc_attenuate,                                     # repeat for wind waves\n",
    "                              ds_2D['p_WW'], ds_2D['h'], zi_block, zb_block,\n",
    "                              input_core_dims=[['N'], [],[],[]],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "\n",
    "# Calculate water surface elevation from depth -------------------------------------\n",
    "ds_2D['zs']    = zb_block2 + h                                                 # water level (surface elevation) = bed level + depth\n",
    "ds_2D['zs_IG'] = zb_block2 + h_IG\n",
    "ds_2D['zs_WW'] = zb_block2 + h_WW\n",
    "\n",
    "ds_out['zs']    = ('t_full',np.ravel(ds_2D['zs']))\n",
    "ds_out['zs_IG'] = ('t_full',np.ravel(ds_2D['zs_IG']))\n",
    "ds_out['zs_WW'] = ('t_full',np.ravel(ds_2D['zs_WW']))\n",
    "ds_out['h']     = ('t_full',np.ravel(h))                                                 # water level (surface elevation) = bed level + depth\n",
    "ds_out['h_IG']  = ('t_full',np.ravel(h_IG))\n",
    "ds_out['h_WW']  = ('t_full',np.ravel(h_WW))\n",
    "\n",
    "ds_out['zs'].attrs    = {'units': 'mm +NAP', 'long_name': 'surface elevation'}   # DAAN: CHECK: MORE METADATA NEEDED?\n",
    "ds_out['zs_IG'].attrs = {'units': 'mm +NAP', 'long_name': 'surface elevation infragrafity waves'}   \n",
    "ds_out['zs_WW'].attrs = {'units': 'mm +NAP', 'long_name': 'surface elevation wind waves'}   \n",
    "ds_2D['zs']    = zb_block2 + h                                                 # water level (surface elevation) = bed level + depth\n",
    "ds_2D['zs_IG'] = zb_block2 + h_IG\n",
    "ds_2D['zs_WW'] = zb_block2 + h_WW\n",
    "\n",
    "# Filter 2: make blocks NaN if more than 25% of the observations had a depth_above_instrument < 0.05 m\n",
    "block_mask = ((ds_2D['zs'] - zi_block2) < 0.05).mean(dim='N') >= 0.25 # to be used for for Welch, calculation wave properties:\n",
    "z_filtered = ds_2D['zs']\n",
    "z_filtered_IG = ds_2D['zs_IG']\n",
    "z_filtered_WW = ds_2D['zs_WW']\n",
    "z_filtered    = z_filtered.where(~block_mask, np.nan)\n",
    "z_filtered_IG = z_filtered_IG.where(~block_mask, np.nan)\n",
    "z_filtered_WW = z_filtered_WW.where(~block_mask, np.nan)\n",
    "\n",
    "# Determine wave spectrum -------------------------------------\n",
    "ufunc_welch = lambda p: welch(p, fs=ds0.sf.values, nperseg=nperseg, detrend='constant', window='hann') # Detrend: is per segment. 1min, about constant, so false used\n",
    "\n",
    "ds_2D['frequencies'], ds_2D['psd'] = xr.apply_ufunc(ufunc_welch,\n",
    "                                                z_filtered,\n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[['f'], ['f']],\n",
    "                                                vectorize=True)\n",
    "ds_2D['frequencies'], ds_2D['psd_IG'] = xr.apply_ufunc(ufunc_welch,\n",
    "                                                z_filtered_IG,\n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[['f'], ['f']],\n",
    "                                                vectorize=True)\n",
    "ds_2D['frequencies'], ds_2D['psd_WW'] = xr.apply_ufunc(ufunc_welch,\n",
    "                                                z_filtered_WW,\n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[['f'], ['f']],\n",
    "                                                vectorize=True)\n",
    "ds_out['psd'] = ds_2D['psd']\n",
    "ds_out['psd_IG'] = ds_2D['psd_IG']\n",
    "ds_out['psd_WW'] = ds_2D['psd_WW']\n",
    "ds_out['psd'].attrs = {'units': 'm^2/Hz', 'long_name': 'Power spectral density (Welch) (f=0.004-1.5 Hz)'}\n",
    "ds_out['psd_IG'].attrs = {'units': 'm^2/Hz', 'long_name': 'Power spectral density (Welch) of long waves (<0.05 Hz)'}\n",
    "ds_out['psd_WW'].attrs = {'units': 'm^2/Hz', 'long_name': 'Power spectral density (Welch) of wind waves (0.05-1.5 Hz)'}\n",
    "\n",
    "# Determine wave parameters ---------------------------\n",
    "ufunc_wave_params = lambda psd: puv.compute_wave_params(ds_2D.f.values, psd, fmin=0.004 , fmax=5)   \n",
    "\n",
    "ds_out['Hm0'], ds_out['Tp'], ds_out['Tm01'], ds_out['Tm02'], ds_out['Tmm10'], ds_out['Tps'] = xr.apply_ufunc(ufunc_wave_params,\n",
    "                                                                          ds_2D['psd'],\n",
    "                                                                          input_core_dims=[['f']],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)\n",
    "ds_out['Hm0_IG'], ds_out['Tp_IG'], ds_out['Tm01_IG'], ds_out['Tm02_IG'], ds_out['Tmm10_IG'], ds_out['Tps_IG'] = xr.apply_ufunc(ufunc_wave_params,\n",
    "                                                                          ds_2D['psd_IG'],\n",
    "                                                                          input_core_dims=[['f']],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)\n",
    "ds_out['Hm0_WW'], ds_out['Tp_WW'], ds_out['Tm01_WW'], ds_out['Tm02_WW'], ds_out['Tmm10_WW'], ds_out['Tps_WW'] = xr.apply_ufunc(ufunc_wave_params,\n",
    "                                                                          ds_2D['psd_WW'],\n",
    "                                                                          input_core_dims=[['f']],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)\n",
    "ds_out['Hm0'].attrs = ds_out['Hm0_IG'].attrs = ds_out['Hm0_WW'].attrs = {'units': 'm', 'long_name': 'significant wave height: Hm0=4sqrt(m0), with m0 zeroth-order spectral moment'}\n",
    "ds_out['Tp'].attrs = ds_out['Tp_IG'].attrs = ds_out['Tp_WW'].attrs = {'units': 's', 'long_name': 'peak wave period'}\n",
    "ds_out['Tm01'].attrs = ds_out['Tm01_IG'].attrs = ds_out['Tm01_WW'].attrs = {'units': 's', 'long_name': 'mean wave period: Tm01 = m0/m1'}\n",
    "ds_out['Tm02'].attrs = ds_out['Tm02_IG'].attrs = ds_out['Tm02_WW'].attrs = {'units': 's', 'long_name': 'mean zero-crossing period: Tm02 = sqrt(m0/m2)'}\n",
    "ds_out['Tmm10'].attrs = ds_out['Tmm10_IG'].attrs = ds_out['Tmm10_WW'].attrs = {'units': 's', 'long_name': 'T-1,0: mean absolute wave period T-1,0 = m_(-1)/m_0'}\n",
    "ds_out['Tps'].attrs = ds_out['Tps_IG'].attrs = ds_out['Tps_WW'].attrs = {'units': 's', 'long_name': 'Smoothed peak wave period'}\n",
    "#plt.plot(ds_2D['Hm0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## skewness of waves ##\n",
    "ufunc = lambda p: puv.compute_SkAs(ds0.sf.values,p,fpfac =None, fbounds = None)     # Daan: check calculation, metadata\n",
    "\n",
    "ds_out['Sk'], ds_out['As'], ds_out['sigma'] =  xr.apply_ufunc(ufunc,\n",
    "                                                ds_2D['p'], \n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[[], [], []],\n",
    "                                                vectorize=True)\n",
    "ds_out['Sk'].attrs = {'units': 'm3', 'long name': 'wave skewness'}\n",
    "ds_out['As'].attrs = {'units': 'm3', 'long name': 'wave asymmetry'}\n",
    "ds_out['sigma'].attrs = {'units': 'm', 'long name': 'standard deviation'}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with compression\n",
    "if not os.path.isdir(os.path.join(experimentFolder,'tailored')):\n",
    "    os.mkdir(os.path.join(experimentFolder,'tailored'))\n",
    "ncFilePath = os.path.join(experimentFolder, 'tailored', ds_out.instrument + ' processed data - period 2 test.nc')\n",
    "encoding = {var: {\"zlib\": True, \"complevel\": 4} for var in list(ds_out.data_vars) + list(ds_out.coords)}  # Apply deflate compression to all variables and coordinates in netCDF\n",
    "ds_out.to_netcdf(ncFilePath, encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with compression, testing compression\n",
    "ds_test = copy.deepcopy(ds_out)  # Make a copy of the dataset to test compression\n",
    "\n",
    "# Round all float variables to 4 decimals before saving\n",
    "#for var in ds_test.data_vars:\n",
    "#   if np.issubdtype(ds_test[var].dtype, np.floating):\n",
    "#       ds_test[var].values = ( np.round(ds_test[var].values, 4) )\n",
    "\n",
    "# ds_test.p.values = np.round(ds_test.p.values)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "#ds_test.zs.values = np.round(ds_test.zs.values,3)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "ds_test.zs.values = np.round(ds_test.zs.values*1000)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "#ds_test.zs.values = np.float32(ds_test.zs.values)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "\n",
    "#ds_test.zs_IG.values = np.round(ds_test.zs_IG.values,3)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "ds_test.zs_IG.values = np.round(ds_test.zs_IG.values*1000)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "#ds_test.zs_IG.values = np.float32(ds_test.zs_IG.values)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "\n",
    "#ds_test.zs_WW.values = np.round(ds_test.zs_WW.values,3)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "ds_test.zs_WW.values = np.round(ds_test.zs_WW.values *1000)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "#ds_test.zs_WW.values = np.float32(ds_test.zs_WW.values)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "\n",
    "ds_test.h.values = np.round(ds_test.h.values*1000)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "ds_test.h_IG.values = np.round(ds_test.h_IG.values*1000)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "ds_test.h_WW.values = np.round(ds_test.h_WW.values*1000)\n",
    "\n",
    "#ds_test = ds_test.drop_vars('p') # and  dropping the old p_rel variable\n",
    "#ds_test = ds_test.drop_vars('zs') # and  dropping the old p_rel variable\n",
    "#ds_test = ds_test.drop_vars('zs_IG') # and  dropping the old p_rel variable\n",
    "#ds_test = ds_test.drop_vars('zs_WW') # and  dropping the old p_rel variable\n",
    "\n",
    "#ds_test.zs.values = np.int32(ds_test.zs.values)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "#ds_test.zs_IG.values = np.int32(ds_test.zs_IG.values)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "#ds_test.zs_WW.values = np.int32(ds_test.zs_WW.values)\n",
    "#ds_test.p.values = np.int32(ds_test.p.values)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "\n",
    "#encoding = {var: {\"zlib\": True, \"complevel\": 4, \"shuffle\": 0} for var in list(ds_test.data_vars) + list(ds_test.coords)}  # Apply deflate compression to all variables and coordinates in netCDF\n",
    "encoding = {var: {\"zlib\": True, \"complevel\": 4} for var in list(ds_test.data_vars) + list(ds_test.coords)}  # Apply deflate compression to all variables and coordinates in netCDF\n",
    "\n",
    "if not os.path.isdir(os.path.join(experimentFolder,'tailored')):\n",
    "    os.mkdir(os.path.join(experimentFolder,'tailored'))\n",
    "ncFilePath = os.path.join(experimentFolder, 'tailored', ds_test.instrument + ' - deflate4, conv zs_all3 with_h.nc')\n",
    "ds_test.to_netcdf(ncFilePath, encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ds_test.zs.values[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
