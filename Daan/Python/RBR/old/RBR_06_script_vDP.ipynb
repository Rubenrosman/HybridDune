{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# sys.path.append(r'C:\\Users\\ruro\\OneDrive - Boskalis\\Documents\\python\\OSSI')\n",
    "from KNMI_readers import read_knmi_uurgeg\n",
    "from scipy.signal import welch\n",
    "\n",
    "import puv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solo_data_reader(dataFile, sf):\n",
    "    '''\n",
    "    Function to read solo datafile.\n",
    "    Returns a dataframe with a time column and pressure column in Pascal\n",
    "    '''\n",
    "    p = []\n",
    "    datt = []\n",
    "    with open(dataFile) as myfile:\n",
    "        for index, line in enumerate(myfile):\n",
    "            if index >= 1:\n",
    "                lin = line.split(',')\n",
    "                datt.append(lin[0])\n",
    "                p.append(float(lin[1]))\n",
    "    p = np.array(p) * 1e4  # dBar to Pa\n",
    "\n",
    "    t = pd.date_range(datt[0], periods=len(datt), freq='{}S'.format(1 / sf))\n",
    "\n",
    "    dfp = pd.DataFrame(data={'p': p}, index=t)\n",
    "\n",
    "    dfp.index.name = 't'\n",
    "    return dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dpoppema\\AppData\\Local\\Temp\\ipykernel_37296\\2651882304.py:16: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  t = pd.date_range(datt[0], periods=len(datt), freq='{}S'.format(1 / sf))\n"
     ]
    }
   ],
   "source": [
    "# # input parameters\n",
    "# # RBRSolo^3\n",
    "sf = 16  #[hz] sampling frequency\n",
    "experimentFolder = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\S3P3 RBR6'                  # path where the data is sitting # Rubens Laptop\n",
    "# experimentFolder = r'U:\\'                  # path where the data is sitting # TUD U-Drive\n",
    "\n",
    "\n",
    "knmiFile = r\"C:\\Users\\dpoppema\\Documents\\GitHub\\HybridDune\\Ruben\\uurgeg_330_2021-2030.txt\"  # path to the KNMI data\n",
    "instrumentName = instrument = 'RBR_06_data1'                                                                              # designated name of the instrument\n",
    "namedatafile = 'RBR6 - 208682_20241227_1744_data.txt'                                                          # name of the datafile\n",
    "dataFile =  os.path.join(experimentFolder, namedatafile)                                                 # path + name datafile\n",
    "serial_number = '202438'                                                                                 # unique serial number of the instrument\n",
    "xRD = 72398.448                                                                                          # x position of placement in field\n",
    "yRD =  452130.253                                                                                        # y position of placement in field\n",
    "zRD_bedlevel =zb = -1.229         # m NAP\n",
    "zRD_sensor = zi =  -0.704         # m NAP\n",
    "\n",
    "\n",
    "# Do the reading from file and cast in xarray dataset\n",
    "dfp = solo_data_reader(dataFile, sf)\n",
    "ds = dfp.to_xarray()\n",
    "ds.p.attrs = {'long_name': 'pressure', 'units': 'Pa'}\n",
    "\n",
    "# Add global attribute metadata\n",
    "ds.attrs = {\n",
    "    'Conventions': 'CF-1.6',\n",
    "    'name': '{}'.format(instrumentName),\n",
    "    'instrument': '{}'.format(instrumentName),\n",
    "    'instrument type': 'Ruskin RBR Solo',\n",
    "    'instrument serial number': '{}'.format(serial_number),\n",
    "    'epsg': 28992,\n",
    "    'x': xRD,\n",
    "    'y': yRD,\n",
    "    'time zone': 'UTC+2',\n",
    "    'coordinate type': 'XYZ',\n",
    "    'summary': 'Hybrid-Dune experiment',\n",
    "    'contact person': 'Ruben Rosman',\n",
    "    'emailadres': 'r.g.c.rosman@student.tudelft.nl',\n",
    "    'construction datetime': datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S)\"),\n",
    "    'version': 'v1',\n",
    "    'version comments': 'constructed with xarray'}\n",
    "\n",
    "# Save to netcdf\n",
    "ncOutDir = os.path.join(experimentFolder, 'raw_netcdf')\n",
    "if not os.path.isdir(ncOutDir):\n",
    "    os.mkdir(ncOutDir)\n",
    "#ds.to_netcdf(os.path.join(ncOutDir, instrumentName + '.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresolution is: 0.016666666666666666\n",
      "O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\S3P3 RBR6\\raw_netcdf\\RBR_06_data1.nc\n",
      "RBR_06_data1\n"
     ]
    }
   ],
   "source": [
    "# frequency resolution in fourier space\n",
    "### delta_f = p_blocks/D_timeframe ###\n",
    "p_blocks = 20\n",
    "D_length = 1200\n",
    "fresolution = p_blocks / D_length\n",
    "print(f'fresolution is: {fresolution}')\n",
    "nperseg = D_length * sf / p_blocks - 0.5 #dim should be len(ds.f); whelch has (nperseg/2 +1)\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "rho = 10277 #kg/m3, for seawater at 9C, avg temp at HKZ measurement station\n",
    "g = 9.81\n",
    "\n",
    "dataFile = os.path.join(experimentFolder,'raw_netcdf',instrumentName + '.nc')\n",
    "print(dataFile)\n",
    "ds0 = xr.open_dataset(dataFile)\n",
    "instr = ds0.instrument\n",
    "\n",
    "# correct for the air pressure fluctuations and drift in the instrument\n",
    "# first we load the data and add it to the dataset\n",
    "dfp = read_knmi_uurgeg(knmiFile, stationNumber=330)\n",
    "dt = ((ds0.t[1] - ds0.t[0]) / np.timedelta64(1, 's')).values # target frequency\n",
    "pAir = dfp['P'].to_xarray().sel(t=slice(ds0.t.min(), ds0.t.max())).resample({'t': '{}S'.format(dt)}).interpolate('linear')\n",
    "ds0['pAir'] = pAir.sel(t=slice(ds0.t.min(), ds0.t.max()))\n",
    "\n",
    "# correct the pressure signal with pAir\n",
    "ds0['pc'] = ds0['p'] -ds0['pAir']\n",
    "# remove all values below 0 Pa\n",
    "# ds0['pc'] = ds0['pc'].where(ds0['pc'] > 0)\n",
    "\n",
    "ds0['pc'].attrs = {'units': 'Pa', 'long_name': 'pressure', 'comments': 'corrected for air pressure'}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# reshape to one row per burst in data array\n",
    "pt = ds0.pc.values\n",
    "nSamples = len(pt)\n",
    "dt = ds0.isel(t=1).t - ds0.isel(t=0).t\n",
    "sf = np.timedelta64(1, 's') / dt.values\n",
    "\n",
    "D_length = '1200S'\n",
    "\n",
    "burstDuration = pd.Timedelta(D_length)  # Burst duration (1200 seconds = 20 minutes)\n",
    "burstLength = int(burstDuration / dt)\n",
    "nBursts = int(np.floor(nSamples / burstLength))\n",
    "\n",
    "pt = pt[:nBursts * burstLength]\n",
    "t = ds0.t[::burstLength]\n",
    "t = t[:nBursts]\n",
    "N = (ds0.t.values[:burstLength] - ds0.t.values[0]) / np.timedelta64(1, 's')\n",
    "# pdb.set_trace()\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# cast into a 2D array\n",
    "ds = xr.Dataset(data_vars={},\n",
    "                coords={'t': t, 'N': N})\n",
    "# copy all data over into this new structure\n",
    "ds['p'] = (('t', 'N'), pt.reshape((nBursts, burstLength)))\n",
    "ds['zi'] = zi\n",
    "ds['zb'] = zb\n",
    "ds['sf'] = sf\n",
    "\n",
    "\n",
    "\n",
    "# Remove water height below 30 cm\n",
    "ds['p'] = ds['p'].where(ds['p'] > 0.3 * (rho * g))\n",
    "\n",
    "# Remove bursts where the standard deviation is too low, indicating the instrument fell dry\n",
    "ds['p'] = ds['p'].where(ds.p.std(dim='N') > 70)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# pdb.set_trace()\n",
    "ds['p'].attrs = {'units': 'Pa +NAP', 'long_name': 'pressure', 'comments': 'corrected for air pressure'}\n",
    "ds['zi'].attrs = {'units': 'm+NAP', 'long_name': 'z instrument'}  # instrument height\n",
    "ds['zb'].attrs = {'units': 'm+NAP', 'long_name': 'z bed'}  # bed level  \n",
    "ds['sf'].attrs = {'units': 'Hz', 'long_name': 'sampling frequency'}\n",
    "ds.attrs = ds0.attrs\n",
    "ds.attrs['summary'] = 'Hybrid-Dune campaign, pressure corrected for air pressure and cast in bursts of 20 minutes'\n",
    "ds['name'] = instr\n",
    "if not os.path.isdir(os.path.join(experimentFolder,'QC')):\n",
    "    os.mkdir(os.path.join(experimentFolder,'QC'))\n",
    "ncFilePath = os.path.join(experimentFolder, 'QC', instr + '.nc')\n",
    "#ds.to_netcdf(ncFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.P.plot()\n",
    "start_time = pd.Timestamp(\"2024-12-13T16:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-27T13:00:00\")\n",
    "plt.xlim(start_time, end_time)\n",
    "pt\n",
    "# plt.xlim(ds0.t.min(), ds0.t.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds0.p.plot()\n",
    "ds0.pc.plot()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,2))\n",
    "ds0.pc.plot()\n",
    "plt.grid()\n",
    "\n",
    "start_time = pd.Timestamp(\"2024-12-17T16:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-23T13:00:00\")\n",
    "plt.xlim(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,2))\n",
    "ds0.pc.plot()\n",
    "plt.grid()\n",
    "\n",
    "start_time = pd.Timestamp(\"2024-12-17T20:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-18T13:00:00\")\n",
    "plt.xlim(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,2))\n",
    "ds0.pc.plot()\n",
    "plt.grid()\n",
    "\n",
    "start_time = pd.Timestamp(\"2024-12-17T20:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-17T20:05:00\")\n",
    "plt.xlim(start_time, end_time)\n",
    "plt.ylim(-100, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrFile = os.path.join(experimentFolder,'QC', instrument +'.nc')\n",
    "ncOutFile = os.path.join(experimentFolder,'tailored', instrument +'.nc')\n",
    "\n",
    "\n",
    "# %% load the raw data from netcdf\n",
    "ds0 = xr.open_dataset(instrFile)\n",
    "\n",
    "#let's remove the bursts where there are only nans\n",
    "ds0 = ds0.dropna(dim='t')\n",
    "\n",
    "# make a new dataset that has an extra dimension to accomodate for the frequency axis\n",
    "ds = xr.Dataset(data_vars={},\n",
    "                coords={'t': ds0.t.values,\n",
    "                        'N': ds0.N.values,\n",
    "                        'f': np.arange(0, ds0.sf.values / 2, fresolution)})\n",
    "ds['f'].attrs = {'units': 'Hz'}\n",
    "ds.attrs = ds0.attrs\n",
    "\n",
    "# put all variables in this new dataset\n",
    "for key in ds0.data_vars:\n",
    "    ds[key] = ds0[key]\n",
    "\n",
    "# extract sampling frequency as explicit variable\n",
    "sf = ds.f.values\n",
    "\n",
    "def remove_outliers(data, threshold=3):\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    mask = np.abs(data - mean) < threshold * std_dev\n",
    "    # filtered_data = np.where(mask, data, mean + threshold * std_dev * np.sign(data - mean))  # Replace outliers with closest value within threshold\n",
    "    filtered_data = np.where(mask, data, np.nan) # Replace outliers with nan\n",
    "    return filtered_data\n",
    "\n",
    "# Create a lambda function to pass the threshold parameter\n",
    "ufunc = lambda x: remove_outliers(x, threshold=3)\n",
    "\n",
    "# Apply the outlier removal function to the pressure data\n",
    "ds['p'] = xr.apply_ufunc(ufunc, \n",
    "                          ds['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "\n",
    "# Interpolate NaN values in the pressure signal\n",
    "ds['p'] = ds['p'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "\n",
    "ds.p.isel(t=111).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the initial number of NaN values\n",
    "initial_nan_count = np.sum(np.isnan(ds['p'].values))\n",
    "print(\"Initial NaN count:\", initial_nan_count)\n",
    "\n",
    "# Interpolating NaN values using linear interpolation\n",
    "ds['p'] = ds['p'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "# Handling any remaining NaN values\n",
    "ds['p'] = ds['p'].ffill(dim='N').bfill(dim='N')\n",
    "\n",
    "# Print the number of NaN values after interpolation\n",
    "remaining_nan_count = np.sum(np.isnan(ds['p'].values))\n",
    "print(\"Remaining NaN count:\", remaining_nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### pressure filtering ####\n",
    "ufunc = lambda x: puv.band_pass_filter2(ds.sf.values, x, fmin=0.004, fmax=1.5)\n",
    "\n",
    "ds['p'] = xr.apply_ufunc(ufunc, \n",
    "                          ds['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "\n",
    "\n",
    "# Compute water depth\n",
    "ds['h'] = (ds['p'] / (rho * g) + (ds['zi'] - ds['zb'])).mean(dim='N')  # Relative to bed level\n",
    "ds['h'].attrs = {'long_name': 'mean water level', 'units': '[m] above bed level'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several wave statistics computations, only based on pressure, for full bandpass\n",
    "onoff=False\n",
    "Threshold= 4\n",
    "\n",
    "\n",
    "ufunc = lambda x, h: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds.sf.values, x, h, \n",
    "    ds.zi.values,\n",
    "    ds.zb.values,\n",
    "    rho=1025,\n",
    "    removeNoise=onoff,\n",
    "    detrend=True)\n",
    "\n",
    "fx, ds['zs'] = xr.apply_ufunc(ufunc, \n",
    "                              ds['p'], ds['h'],\n",
    "                              input_core_dims=[['N'], []],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "\n",
    "ufunc = lambda zs: remove_outliers(zs, threshold=Threshold)\n",
    "\n",
    "# ds['zs'] = xr.apply_ufunc(ufunc, \n",
    "#                           ds['zs'],\n",
    "#                           input_core_dims=[['N']],\n",
    "#                           output_core_dims=[['N']],\n",
    "#                           vectorize=True)\n",
    "\n",
    "# # Interpolate NaN values in the pressure signal\n",
    "# ds['zs'] = ds['zs'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "# Drop values that are below bed level. \n",
    "# ds['zs'] = ds['zs'].where(ds['zs'] >= 0.0, drop=True)\n",
    "\n",
    "ds['zs'].attrs = {'units': 'm', 'long_name': 'surface elevation'}\n",
    "\n",
    "ufunc = lambda p: welch(p, fs=ds.sf.values, nperseg=nperseg, detrend='constant', window='hann')\n",
    "\n",
    "ds['frequencies'], ds['psd'] = xr.apply_ufunc(ufunc,\n",
    "                                                ds['zs'],\n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[['f'], ['f']],\n",
    "                                                vectorize=True)\n",
    "\n",
    "ufunc = lambda psd: puv.compute_wave_params(ds.f.values, psd, fmin=0.004 , fmax=5)\n",
    "\n",
    "ds['Hm0'], ds['Tp'], ds['Tm01'], ds['Tm02'], ds['Tmm10'], ds['Tps'] = xr.apply_ufunc(ufunc,\n",
    "                                                                          ds['psd'],\n",
    "                                                                          input_core_dims=[['f']],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## low frequencies: IG waves ##\n",
    "## now first filter bandpass, then compute wave_params\n",
    "\n",
    "ufunc = lambda x: puv.band_pass_filter2(ds.sf.values, x, fmin=0.004, fmax=0.05)\n",
    "\n",
    "ds['p_low'] = xr.apply_ufunc(ufunc, \n",
    "                          ds['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "\n",
    "ufunc = lambda x, h: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds.sf.values, x, h, \n",
    "    ds.zi.values,\n",
    "    ds.zb.values,\n",
    "    rho=1025,\n",
    "    removeNoise=onoff,\n",
    "    detrend=True)\n",
    "\n",
    "fx, ds['zs_low'] = xr.apply_ufunc(ufunc, \n",
    "                              ds['p_low'], ds['h'],\n",
    "                              input_core_dims=[['N'], []],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "\n",
    "# ufunc = lambda zs: remove_outliers(zs, threshold=Threshold)\n",
    "\n",
    "# ds['zs_low'] = xr.apply_ufunc(ufunc, \n",
    "#                           ds['zs_low'],\n",
    "#                           input_core_dims=[['N']],\n",
    "#                           output_core_dims=[['N']],\n",
    "#                           vectorize=True)\n",
    "\n",
    "# ds['zs_low'] = ds['zs_low'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "# ds['zs_low'] = ds['zs_low'].where(ds['zs_low'] >= 0.0, drop=True)\n",
    "\n",
    "ds['zs_low'].attrs = {'units': 'm', 'long_name': 'surface elevation low freq.'}\n",
    "\n",
    "\n",
    "ufunc = lambda p: welch(p, fs=ds.sf.values, nperseg=nperseg, detrend='constant', window='hann')\n",
    "\n",
    "ds['frequencies_low'], ds['psd_low'] = xr.apply_ufunc(ufunc,\n",
    "                                                ds['zs_low'],\n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[['f'], ['f']],\n",
    "                                                vectorize=True)\n",
    "\n",
    "ufunc = lambda psd: puv.compute_wave_params(ds.f.values, psd, fmin=0.004 , fmax=0.05)\n",
    "\n",
    "ds['Hm0_low'], ds['Tp_low'], ds['Tm01_low'], ds['Tm02_low'], ds['Tmm10_low'], ds['Tps_low'] = xr.apply_ufunc(ufunc,\n",
    "                                                                          ds['psd_low'],\n",
    "                                                                          input_core_dims=[['f']],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## High frequencies: wind-waves ##\n",
    "## now first filter bandpass, then compute wave_params\n",
    "\n",
    "ufunc = lambda x: puv.band_pass_filter2(ds.sf.values, x, fmin=0.05, fmax=5)\n",
    "\n",
    "ds['p_high'] = xr.apply_ufunc(ufunc, \n",
    "                          ds['p'],\n",
    "                          input_core_dims=[['N']],\n",
    "                          output_core_dims=[['N']],\n",
    "                          vectorize=True)\n",
    "\n",
    "ufunc = lambda x, h: puv.attenuate_signal(\n",
    "    'pressure', \n",
    "    ds.sf.values, x, h, \n",
    "    ds.zi.values,\n",
    "    ds.zb.values,\n",
    "    rho=1025,\n",
    "    removeNoise=onoff,\n",
    "    detrend=True)\n",
    "\n",
    "t, ds['zs_high'] = xr.apply_ufunc(ufunc, \n",
    "                              ds['p_high'], ds['h'],\n",
    "                              input_core_dims=[['N'], []],\n",
    "                              output_core_dims=[['f'], ['N']],\n",
    "                              vectorize=True)\n",
    "\n",
    "ufunc = lambda zs: remove_outliers(zs, threshold=Threshold)\n",
    "\n",
    "# ds['zs_high'] = xr.apply_ufunc(ufunc, \n",
    "#                           ds['zs_high'],\n",
    "#                           input_core_dims=[['N']],\n",
    "#                           output_core_dims=[['N']],\n",
    "#                           vectorize=True)\n",
    "\n",
    "# ds['zs_high'] = ds['zs_high'].interpolate_na(dim='N', method='linear')\n",
    "\n",
    "# ds['zs_high'] = ds['zs_high'].where(ds['zs_high'] >= 0.0, drop=True)\n",
    "\n",
    "ds['zs_high'].attrs = {'units': 'm', 'long_name': 'surface elevation high freq.'}\n",
    "\n",
    "\n",
    "\n",
    "ufunc = lambda p: welch(p, fs=ds.sf.values, nperseg=nperseg, detrend='constant', window='hann')\n",
    "\n",
    "ds['frequencies_high'], ds['psd_high'] = xr.apply_ufunc(ufunc,\n",
    "                                                ds['zs_high'],\n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[['f'], ['f']],\n",
    "                                                vectorize=True)\n",
    "\n",
    "ufunc = lambda psd: puv.compute_wave_params(ds.f.values, psd, fmin=0.05 , fmax=5)\n",
    "\n",
    "ds['Hm0_high'], ds['Tp_high'], ds['Tm01_high'], ds['Tm02_high'], ds['Tmm10_high'], ds['Tps_high'] = xr.apply_ufunc(ufunc,\n",
    "                                                                          ds['psd_high'],\n",
    "                                                                          input_core_dims=[['f']],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## skewness of waves ##\n",
    "ufunc = lambda p: puv.compute_SkAs(sf,p,fpfac =None, fbounds = None)\n",
    "\n",
    "ds['Sk'], ds['As'], ds['sig'] =  xr.apply_ufunc(ufunc,\n",
    "                                                ds['p'], \n",
    "                                                input_core_dims=[['N']],\n",
    "                                                output_core_dims=[[], [], []],\n",
    "                                                vectorize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all variables with dimension 'N'\n",
    "# for var in ds.data_vars:\n",
    "#     if 'N' in ds[var].dims:\n",
    "#         ds[var] = ds[var].stack(t_N=('t', 'N'))\n",
    "\n",
    "# %% write to file\n",
    "# we strip all information on burst scale from the dataset to reduce size (and this info is already present in the raw_netcdf version of the data)\n",
    "# dsTailored = ds.drop_dims('N')\n",
    "dsTailored = ds\n",
    "\n",
    "\n",
    "if not os.path.isdir(os.path.join(experimentFolder,'tailored')):\n",
    "    os.mkdir(os.path.join(experimentFolder,'tailored'))\n",
    "ncFilePath = os.path.join(experimentFolder, 'tailored', ds0.instrument + '.nc')\n",
    "dsTailored.to_netcdf(ncFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continuous time array\n",
    "t_continuous = np.array([t + np.timedelta64(int(n), 's') for t in ds.t.values for n in ds.N.values])\n",
    "\n",
    "# Flatten the burst structure for plotting\n",
    "zs_flat = ds.zs.values.flatten()\n",
    "zs_low_flat = ds.zs_low.values.flatten()\n",
    "zs_high_flat = ds.zs_high.values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.plot(t_continuous, zs_flat, label='zs', alpha=0.7, linewidth=0.9)\n",
    "plt.plot(t_continuous, zs_high_flat, label='zs_high', alpha=0.7, linewidth=0.9)\n",
    "plt.plot(t_continuous, zs_low_flat, label='zs_low', alpha=0.7, linewidth=0.9)\n",
    "\n",
    "ds.h.plot(label='Waterlevel')\n",
    "\n",
    "\n",
    "\n",
    "# give values below y=0 a different color\n",
    "# plt.fill_between(t_continuous, zs_flat, 0, where=zs_flat < 0, color='grey', alpha=1, zorder=4, linewidth=1.5)\n",
    "# plt.fill_between(t_continuous, zs_low_flat, 0, where=zs_low_flat < 0, color='grey', alpha=1, zorder=4, linewidth=1.5)\n",
    "# plt.fill_between(t_continuous, zs_high_flat, 0, where=zs_high_flat < 0, color='grey', alpha=1, zorder=4, linewidth=1.5)\n",
    "plt.axhline(y=0, color='k', linestyle='--', label='Bed level')\n",
    "\n",
    "# Set x-axis limits using specific date stamps\n",
    "start_time = pd.Timestamp(\"2024-12-18T12:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-21T00:00:00\")\n",
    "# plt.xlim(start_time, end_time)\n",
    "\n",
    "plt.axhline((ds.zi-ds.zb).values, color='k', linestyle='--', label='Instrument height above bed')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Surface Elevation (m)')\n",
    "plt.title('Surface Elevation vs Time RBR06 2024-12-16 to 2024-12-27')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hmo \n",
    "plt.figure(figsize=(15, 8))\n",
    "ds.Hm0.plot(label='Hm0')\n",
    "ds.Hm0_low.plot(label=f'Hm0_low (mean={ds.Hm0_low.mean().values:.3g} m)')\n",
    "\n",
    "ds.Hm0_high.plot(label='Hm0_high')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Hm0 (m)')\n",
    "plt.title('Hm0 vs Time')\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis limits using specific date stamps\n",
    "start_time = pd.Timestamp(\"2024-12-18T12:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-21T00:00:00\")\n",
    "# plt.xlim(start_time, end_time)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hs and h\n",
    "plt.figure(figsize=(16, 3))\n",
    "ds.h.plot(label='Waterlevel')\n",
    "# (ds.h + ds.zb).plot(label='Waterlevel + zb (NAP)')\n",
    "\n",
    "# Interpolate between points\n",
    "ds.Hm0.plot(label=f'Hm0 (mean={ds.Hm0.mean().values:.3g} m)')\n",
    "ds.Hm0_low.plot(label=f'Hm0_low (mean={ds.Hm0_low.mean().values:.3g} m)')\n",
    "\n",
    "# ds.Hm0_high.plot(label='Hm0_high')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('(m)')\n",
    "plt.title('Hm0 vs Time')\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis limits using specific date stamps\n",
    "start_time = pd.Timestamp(\"2024-12-21T16:00:00\")\n",
    "end_time = pd.Timestamp(\"2024-12-23T13:00:00\")\n",
    "# plt.xlim(start_time, end_time)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 111\n",
    "end =120\n",
    "\n",
    "plt.figure(figsize=(16, 2))\n",
    "(ds.zs.isel(t=t)-ds.zs.isel(t=t).mean()).plot(label = f'Water elevation; Hm0: {ds.Hm0.isel(t=t).values:.3g}m')\n",
    "# (ds.zs.isel(t=t)-ds.h.isel(t=t).mean()).plot(label = f'Water elevation; Hm0: {ds.Hm0.isel(t=t).values:.3g}m')\n",
    "plt.grid()\n",
    "plt.xlim(0,end)\n",
    "plt.ylabel(f'\\u03B7 [m]')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.figure(figsize=(16, 2))\n",
    "ds.zs.isel(t=t).plot(color='grey', label= 'total elevation')\n",
    "ds.zs_low.isel(t=t).plot(color='green', label = f'infragravity waves; Hm0: {ds.Hm0_low.isel(t=t).values:.3g}m')\n",
    "plt.grid()\n",
    "plt.xlim(0,end)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.figure(figsize=(16, 2))\n",
    "ds.zs.isel(t=t).plot(color='grey', label= 'total elevation')\n",
    "ds.zs_high.isel(t=t).plot(color='red', label = f'wind waves; Hm0: {ds.Hm0_high.isel(t=t).values:.3g}m')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim(0,end)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to remove outliers\n",
    "# def remove_outliers(data, threshold=3):\n",
    "#     mean = np.mean(data)\n",
    "#     std_dev = np.std(data)\n",
    "#     filtered_data = [x if abs(x - mean) < threshold * std_dev else mean for x in data]\n",
    "#     return np.array(filtered_data)\n",
    "\n",
    "def remove_outliers(data, threshold=3):\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    mask = np.abs(data - mean) < threshold * std_dev\n",
    "    # filtered_data = np.where(mask, data, mean + threshold * std_dev * np.sign(data - mean))  # Replace outliers with closest value within threshold\n",
    "    filtered_data = np.where(mask, data, np.nan) # Replace outliers with nan\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "data = ds.zs.isel(t=t).values  # Extract the data values for the selected time index t\n",
    "\n",
    "# Remove outliers from the data\n",
    "cleaned_data = remove_outliers(data)\n",
    "\n",
    "# Interpolate NaN values in the pressure signal\n",
    "# cleaned_data = cleaned_data.interpolate_na(method='linear')\n",
    "\n",
    "# Calculate the mean of the cleaned data\n",
    "mean_cleaned_data = np.mean(cleaned_data)\n",
    "\n",
    "# Plotting the cleaned data\n",
    "plt.figure(figsize=(16, 2))\n",
    "plt.plot(ds.N, cleaned_data - mean_cleaned_data, label=f'Water elevation; Hm0: {ds.Hm0.isel(t=t).values:.3g}m')\n",
    "plt.grid()\n",
    "plt.xlim(0, 200)\n",
    "plt.ylabel(f'\\u03B7 [m]')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "print(len(cleaned_data)/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "t=111\n",
    "freq = ds.frequencies.isel(t=t)\n",
    "psd = ds.psd.isel(t=t)\n",
    "\n",
    "\n",
    "# Calculate confidence intervals\n",
    "nBlocks = len(ds.zs.isel(t=t)) // nperseg  # Estimate the number of blocks used by Welch's method\n",
    "edf = round(nBlocks * 2)     # Degrees of freedom (approximately 2 per segment)\n",
    "alpha = 0.1                  # 90% confidence level\n",
    "\n",
    "confLow = edf / chi2.ppf(1 - alpha / 2, edf)  # Lower confidence limit\n",
    "confUpper = edf / chi2.ppf(alpha / 2, edf)    # Upper confidence limit\n",
    "\n",
    "# Confidence interval bounds for PSD\n",
    "psd_lower = psd * confLow\n",
    "psd_upper = psd * confUpper\n",
    "\n",
    "\n",
    "\n",
    "### background plot \n",
    "freq_bg, psd_bg = welch(ds.zs.isel(t=t).values, fs=16, nperseg=19200, detrend='constant', window='hann')\n",
    "nBlocks_bg = len(ds.zs.isel(t=t).values) // 19200  # Estimate the number of blocks used by Welch's method\n",
    "edf_bg = round(nBlocks * 2)     # Degrees of freedom (approximately 2 per segment)\n",
    "confLow_bg = edf / chi2.ppf(1 - alpha / 2, edf)  # Lower confidence limit\n",
    "confUpper_bg = edf / chi2.ppf(alpha / 2, edf)    # Upper confidence limit\n",
    "psd_lower_bg = psd_bg * confLow_bg\n",
    "psd_upper_bg = psd_bg * confUpper_bg\n",
    "# plt.plot(freq_bg, psd_upper_bg, color='gray', linestyle= '--')\n",
    "plt.fill_between(freq_bg, psd_lower_bg, psd_upper_bg, color='gray', alpha=0.3, label='Raw spectrum', linestyle='--')\n",
    "\n",
    "### plotting\n",
    "plt.fill_between(freq, psd_lower, psd_upper, color='black', alpha=0.3, label='90% Confidence Interval')\n",
    "plt.semilogy(freq, psd, label='Power Density Spectrum')\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD (mÂ²/Hz)')\n",
    "plt.title(f'Power Spectral Density using Welch\\'s Method for t ={t}')\n",
    "plt.grid()\n",
    "plt.yscale('linear')\n",
    "# plt.xscale('log')\n",
    "plt.xscale('linear')\n",
    "plt.xlim(0,0.6)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_time_index(ds, specific_time):\n",
    "    \"\"\"\n",
    "    Function to find the index 't' for a specific time in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    ds (xarray.Dataset): The dataset containing the time dimension.\n",
    "    specific_time (str or datetime): The specific time to find the index for.\n",
    "    \n",
    "    Returns:\n",
    "    int: The index corresponding to the specific time.\n",
    "    \"\"\"\n",
    "    specific_time = np.datetime64(specific_time)\n",
    "    time_index = np.where(ds.t.values == specific_time)[0]\n",
    "    \n",
    "    if len(time_index) == 0:\n",
    "        raise ValueError(f\"Time {specific_time} not found in the dataset.\")\n",
    "    \n",
    "    return time_index[0]\n",
    "\n",
    "# Example usage\n",
    "specific_time = \"2024-12-20T12:00:00\"\n",
    "t_index = find_time_index(ds, specific_time)\n",
    "print(f\"The index for the specific time {specific_time} is {t_index}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
