{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# sys.path.append(r'C:\\Users\\ruro\\OneDrive - Boskalis\\Documents\\python\\OSSI')\n",
    "\n",
    "sys.path.append(r'C:\\Users\\dpoppema\\Documents\\GitHub\\HybridDune\\Ruben\\Pressure_sensors\\S1\\RBR_05')\n",
    "from scipy.signal import welch\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import puv \n",
    "from copy import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solo_data_reader(dataFile, sf):\n",
    "    '''\n",
    "    Function to read solo datafile.\n",
    "    Returns a dataframe with a time column and pressure column in Pascal\n",
    "    '''\n",
    "    p = []\n",
    "    datt = []\n",
    "    with open(dataFile) as myfile:\n",
    "        for index, line in enumerate(myfile):\n",
    "            if index >= 1:\n",
    "                lin = line.split(',')\n",
    "                datt.append(lin[0])\n",
    "                p.append(float(lin[1]))\n",
    "    p = np.array(p) * 1e4  # dBar to Pa\n",
    "\n",
    "    t = pd.date_range(datt[0], periods=len(datt), freq='{}s'.format(1 / sf))\n",
    "\n",
    "    dfp = pd.DataFrame(data={'p': p}, index=t)\n",
    "\n",
    "    dfp.index.name = 't'\n",
    "    return dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movmean(x, N):\n",
    "    # calculate moving mean. NB: this divides values at the edges by the window length, instead of the available number of values\n",
    "    y = uniform_filter1d(x, size=N, mode='constant') # for even window: backward avg. So window 2: x_m(i)=[x(i-1)+x(i)]/2. x_m(i=1) = x(i=1)/2\n",
    "\n",
    "    # compensate edges for number of values, i.e. the truncated window length\n",
    "    S1 = np.arange(np.ceil(N/2), N)\n",
    "    S2 = np.ones(len(x)-N+1)*N\n",
    "    S3 = np.arange(N-1, np.floor(N/2), -1)\n",
    "    S = np.concatenate((S1, S2, S3)) \n",
    "    return y * N / S\n",
    "    # for 2D inspiration, see https://stackoverflow.com/questions/23000260/numpy-two-dimensional-moving-average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD RAW DATA, SAVE TO NETCDF\n",
    "# Physical constants -----------------------------------------------------------------------------------\n",
    "rho = 1027 #kg/m3, for seawater at 9C, avg temp at HKZ measurement station\n",
    "g = 9.8125  # value Zandmotor\n",
    "\n",
    "# # input parameters per file ----------------------------------\n",
    "subfolder_in_all = ['refP1 RBR4', 'S1P3 RBR5', 'S2P3 RBR1', 'S3P3 RBR6', 'S4P3 RBR2','S1P2 RBR3'] # subfolder where file is sitting within experimentFolder (on O drive Daan)\n",
    "instrumentname_all = subfolder_in_all \n",
    "namedatafile_all = ['S4 - 202441_20241227_1702_data.txt',       # name of the datafile\n",
    "                    'S5 - 208681_20241227_1715_data.txt',\n",
    "                    'RBR 1 - 202438_20241223_2203_data.txt',\n",
    "                    'RBR6 - 208682_20241227_1744_data.txt',\n",
    "                    'RBR2 - 202439_20241227_1624_data.txt',\n",
    "                    'S3 - 202440_20241227_1627_data.txt']                                                          \n",
    "#                   RBR4(ref),       RBR5,       RBR1,       RBR6,       RBR2,       RBR3\n",
    "sf_all            = [       8,         16,          8,         16,          8,          8]              # [hz] sampling frequency\n",
    "offset_all        = [    -597,       -225,        315,         30,        353,        124]              # [Pa] offset to be added to the pressure data, for instrument calibration\n",
    "xRD_all           = [  np.nan,  72429.072,  72412.478,  72398.360,  72382.977,  72444.875]              # x position of placement in field\n",
    "yRD_all           = [  np.nan, 452174.014, 452150.390, 452130.334, 452111.119, 452163.053]              # y position of placement in field\n",
    "zi_all            = [  np.nan,     -0.463,     -0.630,     -0.704,     -0.910,      0.301]              # z position of instrument (sensor) in field\n",
    "serial_number_all = ['202441',   '208681',   '202438',   '208682',   '202439',   '202440']              # unique serial number of the instrument\n",
    "\n",
    "zb_all = np.array([ [np.nan, np.nan, np.nan],\n",
    "                    [-0.969, -0.880, -0.933],\n",
    "                    [-1.142, -0.957, -0.910],\n",
    "                    [-1.229, -1.103, -0.964],\n",
    "                    [-1.291, -1.199, -1.120],\n",
    "                    [-0.023, -0.029, -0.007] ])  \n",
    "t_zb_all = pd.to_datetime(['2024-12-17 10:30',  # Appies to all RBRs except refP1 RBR4R.\n",
    "                           '2024-12-20 12:20',\n",
    "                           '2024-12-23 12:00'])\n",
    "\n",
    "# convert RD coordinates to local coordinates\n",
    "xy_RD = np.array([xRD_all, yRD_all]).T\n",
    "a = np.deg2rad(36)\n",
    "transformation_matrix = np.array([ [np.cos(a), np.sin(a)],[-np.sin(a), np.cos(a)] ])\n",
    "xy_loc = ( xy_RD - [71683.584, 452356.055] ) @ transformation_matrix\n",
    "x_loc_all = xy_loc.T[0]\n",
    "y_loc_all = xy_loc.T[1]\n",
    "\n",
    "# # input parameters general ---------------------------------------------\n",
    "experimentFolder = r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1'                   # path where the data is sitting\n",
    "\n",
    "# # Define input parameters for file i   (start loop) -----------------------\n",
    "for i in [0]:#range(0,6):\n",
    "    sf = sf_all[i]  #[hz] sampling frequency\n",
    "    data_inDir = os.path.join(experimentFolder, subfolder_in_all[i])\n",
    "    namedatafile = namedatafile_all[i]\n",
    "    instrumentName = instrumentname_all[i]                                                              # designated name of the instrument\n",
    "    xRD = xRD_all[i]                                                                                    # x position of placement in field\n",
    "    yRD =  yRD_all[i]                                                                                  # y position of placement in field\n",
    "    x_loc = x_loc_all[i]                                                                                # x position of instrument in local coordinate system [m]\n",
    "    y_loc = y_loc_all[i]                                                                                # y position of instrument in local coordinate system [m]\n",
    "    if i >= 1: # instrument 0 is reference sensor, instrument and bed height only applicable for sensors installed at beach\n",
    "        zi = zi_all[i]\n",
    "        zb = zb_all[i] \n",
    "        t_zb = t_zb_all  # bed height: n/a for iteration 0 (ref sensor), the same for all other RBRs\n",
    "        t_zi =  pd.to_datetime('2024-12-17 10:30')\n",
    "\n",
    "    # Do the reading from file and cast in xarray dataset ----------------\n",
    "    dataFile =  os.path.join(data_inDir, namedatafile)                                                 # path + name datafile\n",
    "    dfp = solo_data_reader(dataFile, sf)\n",
    "    ds = dfp.to_xarray()\n",
    "\n",
    "    # add dimension t_zb and variables zb, zi and t_zi, for bed level observations over time and instrument height\n",
    "    if i >= 1: # instrument 0 is reference sensor, instrument and bed height only applicable for the remaining sensors\n",
    "        ds['t_zb'] = t_zb # t_zb is a vector instead of scalar, so this syntax adds a dimension (instead of variable)\n",
    "        ds['zb'] = ('t_zb',zb)                                   # initial bed level [m NAP]\n",
    "        ds['t_zi'] = t_zi                                        # time that zi was measured\n",
    "        ds['zi'] = zi                                            # instrument height [m NAP]\n",
    "\n",
    "    # Add instrument variables for metadata: location, frequency\n",
    "    ds['x_RD'] = xRD                                         # x position of instrument, in RDNAP coordinates [m]\n",
    "    ds['y_RD'] = yRD                                         # y position of instrument, in RDNAP coordinates [m]\n",
    "    ds['x_local'] = x_loc                                    # x position of instrument, in local coordinate system [m]\n",
    "    ds['y_local'] = y_loc                                    # y position of instrument, in local coordinate system [m] \n",
    "    ds['sf'] = sf                                            # sampling frequency [hz]\n",
    "\n",
    "    # Add global attribute metadata\n",
    "    ds.attrs = {\n",
    "        'Conventions': 'CF-1.6',\n",
    "        'name': 'Pressure sensor ' + instrumentName[0:-4] + 'RBR, period 1',\n",
    "        'instrument': 'Pressure sensor ' + instrumentName,\n",
    "        'instrument type': 'Ruskin RBR Solo',\n",
    "        'instrument serial number': '{}'.format(serial_number_all[i]),\n",
    "        'time zone': 'UTC+2',\n",
    "        'start time': pd.to_datetime(ds.t.values[0]).strftime(\"%d-%b-%Y %H:%M:%S\"),\n",
    "        'end time':   pd.to_datetime(ds.t.values[-1]).strftime(\"%d-%b-%Y %H:%M:%S\"),\n",
    "        'summary': 'HybridDune experiment: raw pressure data',\n",
    "        'contact person': 'Daan Poppema',\n",
    "        'emailadres': 'd.w.poppema@tudelft.nl',\n",
    "        'construction datetime': datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\"),\n",
    "        'version': 'v1',\n",
    "        'comment_1': 'constructed with xarray',\n",
    "        'url of online dataset': 'ADD LATER'}      # DAAN: ADD URL LATER\n",
    "    \n",
    "    # Add attributes to variables for metadata\n",
    "    local_coord_sys = 'x=cross-shore (positive=landward); y=alongshore (positive is to north-east); (800,200) is the southern seaward corner of the containers'\n",
    "    coord_conv   = '(0,0) local is (71683.584,452356.055) RD coordinates; local x-axis is 36° clockwise from RD x-axis; i.e. [x_loc y_loc] = [x_RD y_RD] - [x0 y0] .* [cosd(36) sind(36); -sind(36) cosd(36)]'\n",
    "    ds.p.attrs = {'units': 'Pa', 'long_name': 'pressure', 'comments': 'raw data'}\n",
    "    ds.x_RD.attrs = {'units': 'm', 'long_name': 'x position of instrument in RDNAP coordinates', 'epsg': 28992}\n",
    "    ds.y_RD.attrs = {'units': 'm', 'long_name': 'y position of instrument in RDNAP coordinates', 'epsg': 28992}\n",
    "    ds.x_local.attrs = {'units': 'm', 'long_name': 'cross-shore position of instrument in local coordinate system','local_coordinate_system': local_coord_sys, 'coordinate_conversion': coord_conv}\n",
    "    ds.y_local.attrs = {'units': 'm', 'long_name': 'alongshore position of instrument in local coordinate system','local_coordinate_system': local_coord_sys, 'coordinate_conversion': coord_conv}\n",
    "    ds.sf.attrs = {'units': 'Hz', 'long_name': 'sampling frequency'}\n",
    "    if i >= 1: # instrument 0 is reference sensor, instrument and bed height only applicable for the remaining sensors\n",
    "        ds.zi.attrs = {'units': 'm +NAP', 'long_name': 'elevation of sensor'}  # instrument height\n",
    "        ds.zb.attrs = {'units': 'm +NAP', 'long_name': 'bed level'}  \n",
    "        ds.t_zi.attrs = {'long name': 'time that instrument elevation was measured'}\n",
    "        ds.t_zb.attrs = {'long name': 'time that bed level at instrument was measured'}\n",
    "\n",
    "    # Save to netcdf -------------------------------\n",
    "    ds.p.values = np.round(ds.p.values)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "    encoding = {var: {\"zlib\": True, \"complevel\": 4} for var in list(ds.data_vars) + list(ds.coords)}  # Apply deflate compression to all variables and coordinates in netCDF\n",
    "    \n",
    "    ncOutDir = os.path.join(experimentFolder, 'raw NetCDF')\n",
    "    if not os.path.isdir(ncOutDir):\n",
    "        os.mkdir(ncOutDir)\n",
    "    #ds.to_netcdf(os.path.join(ncOutDir, instrumentName + ' raw data - period 1.nc'), encoding=encoding)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.p.values = np.round(ds.p.values)    # Round pressure to 1 Pa = 0.1 mm (file size 7 times smaller)\n",
    "encoding = {var: {\"zlib\": True, \"complevel\": 4} for var in list(ds.data_vars) + list(ds.coords)}  # Apply deflate compression to all variables and coordinates in netCDF\n",
    "\n",
    "ds.to_netcdf(os.path.join(ncOutDir, instrumentName + ' raw data - period 1 round deflate4.nc'), encoding=encoding)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CALCULATE ATMOSPHERIC AIR PRESSURE, ...\n",
    "# Set smoothing window for atmpospheric pressure\n",
    "t_smooth_air = 10 # [s]     # measured with 8 hz. But p_water and p_air are measured up to 100m apart (and p_air inside). Affected different by wind gusts, so filter out short-term variation\n",
    "\n",
    "# Open raw data file  of reference sensor -------------------------------------------------------------------\n",
    "dataFile =r'O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\raw NetCDF\\refP1 RBR4 raw data - period 1.nc'\n",
    "ds = xr.open_dataset(dataFile)\n",
    "\n",
    "# crop dataset to the time range of interest. 5 RBRs with about the same end time, make exactly the same\n",
    "t0 = datetime(2024, 12, 17, 11, 0, 0)         # first full hour that all 5 instruments were installed at the beach\n",
    "t_end = datetime(2024, 12, 23, 13, 0)         # last full hour that all 5 instruments were installed at the beach\n",
    "# t0 = datetime(2024, 12, 12, 9, 0, 0)        # old lines: cropped files to the same length, but contained obs before instruments were installed at beach, ,,,\n",
    "# t_end = datetime(2024, 12, 27, 16, 20, 0)   # and after they were already removed\n",
    "ds_air_8hz = ds.sel(t=slice(t0, t_end))\n",
    "tAir_8hz = ds_air_8hz['t']\n",
    "\n",
    "# Determine moving average. \n",
    "pAir_smooth_8hz = movmean(ds_air_8hz['p'], 8*t_smooth_air) # smooth over 8hz * n seconds\n",
    "\n",
    "# interpolate for 16hz sensors\n",
    "tAir_16hz   = pd.date_range(t0, t_end, freq='{}s'.format(1 / 16)) # 16hz time vector\n",
    "pAir_smooth_16hz = np.interp(tAir_16hz, tAir_8hz, pAir_smooth_8hz) # interpolate to 16hz time vector\n",
    "\n",
    "# Add to dataset\n",
    "ds_air_8hz['pAir_smooth'] = (('t'), pAir_smooth_8hz )\n",
    "ds_air_16hz = xr.Dataset( # make dataset for 16hz air pressure\n",
    "    data_vars={'pAir_smooth': (('t',), pAir_smooth_16hz)},\n",
    "    coords={'t': tAir_16hz} )\n",
    "\n",
    "# Make shorter series for RBR1 (instrument turned off earlier)\n",
    "t_end_RBR1 = t_end                              # not needed anymore. But RBR1 was turned off 0.5day after de-installation from beach, the rest 4 days later. So old code to deal with\n",
    "#t_end_RBR1 = datetime(2024, 12, 23, 22, 4, 36)  # RBR1 stopping earlier than the rest. Now all cropped to the same length anyway\n",
    "ds_air_8hz_RBR1 = ds_air_8hz.sel(t=slice(t0, t_end_RBR1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1P3 RBR5\n",
      "O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\raw NetCDF\\S1P3 RBR5.nc\n",
      "S2P3 RBR1\n",
      "O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\raw NetCDF\\S2P3 RBR1.nc\n",
      "S3P3 RBR6\n",
      "O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\raw NetCDF\\S3P3 RBR6.nc\n",
      "S4P3 RBR2\n",
      "O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\raw NetCDF\\S4P3 RBR2.nc\n",
      "S1P2 RBR3\n",
      "O:\\HybridDune experiment\\data RBR, OSSI\\copy RBR Udrive series1\\raw NetCDF\\S1P2 RBR3.nc\n"
     ]
    }
   ],
   "source": [
    "# Instrument to be corrected, filtered\n",
    "\n",
    "for i in [1,2,3,4,5]:\n",
    "    instrumentName = instrumentname_all[i]                                                                               # designated name of the instrument\n",
    "    print(instrumentName)\n",
    "    dataFile = os.path.join(experimentFolder,'raw NetCDF',instrumentName + ' raw data - period 1.nc')\n",
    "    print(dataFile)\n",
    "\n",
    "    ds0 = xr.open_dataset(dataFile)\n",
    "    # crop air pressure and instrument dataset to the same time\n",
    "    # if i != 2:  # S2P3 RBR1 has a shorter time series  # skip: old code for when RBR1 was treated separately. Now use line below instead\n",
    "    #    ds0 = ds0.sel(t=slice(t0, t_end))  # crop dataset to the time range of interest\n",
    "    ds0 = ds0.sel(t=slice(t0, t_end))  # crop dataset to the time range of interest\n",
    "\n",
    "    # Relative pressure: correct the pressure signal with pAir\n",
    "    if i == 2: # RBR1\n",
    "        ds0['p_rel'] = ds0['p'] + offset_all[i] - (ds_air_8hz_RBR1['pAir_smooth'] + offset_all[0])  # relative pressure. Add calibration offset per instrument. RBR1 has a shorter time series, treated separately\n",
    "    elif sf_all[i] == 8:    \n",
    "        ds0['p_rel'] = ds0['p'] + offset_all[i] - (ds_air_8hz['pAir_smooth']   + offset_all[0])\n",
    "    else:\n",
    "        ds0['p_rel'] = ds0['p'] + offset_all[i] - (ds_air_16hz['pAir_smooth'] + offset_all[0])\n",
    "        ds_air_16hz['pAir_smooth']\n",
    "\n",
    "    cal_text = '{}'.format(offset_all[i]) + ' Pa added to raw pressure of instrument (and ' + '{}'.format(offset_all[0]) + ' Pa added to air pressure of sensor refP1), based on the period between 12dec 20:00 and 13dec 6:00 that all RBRs measured just atmospheric pressure'\n",
    "    ds0['p_rel'].attrs = {'units': 'Pa', 'long_name': 'Relative pressure', 'comments': 'corrected for air pressure and calibrated','calibration': cal_text}\n",
    "    ds0.attrs['summary'] = 'Hybrid-Dune campaign: pressure corrected for air pressure'\n",
    "    ds0.attrs['start time'] = pd.to_datetime(ds.t.values[0]).strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "    ds0.attrs['end time'] =   pd.to_datetime(ds.t.values[-1]).strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "\n",
    "    if not os.path.isdir(os.path.join(experimentFolder,'QC')):\n",
    "        os.mkdir(os.path.join(experimentFolder,'QC'))\n",
    "    ncFilePath = os.path.join(experimentFolder, 'QC', instrumentName + ' p_rel - period 1.nc')\n",
    "    encoding = {var: {\"zlib\": True, \"complevel\": 4} for var in list(ds0.data_vars) + list(ds0.coords)}  # Apply deflate compression to all variables and coordinates in netCDF\n",
    "    ds0.to_netcdf(ncFilePath, encoding=encoding) # save to netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 Pa added to raw pressure of instrument (and \n"
     ]
    }
   ],
   "source": [
    "#'{}'.format(serial_number)\n",
    "cal_text = '{}'.format(offset_all[i]) + ' Pa added to raw pressure of instrument (and '\n",
    "\n",
    "print(cal_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
