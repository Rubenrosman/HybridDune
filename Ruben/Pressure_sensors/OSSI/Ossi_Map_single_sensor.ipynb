{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\ruro\\OneDrive - Boskalis\\Documents\\python\\OSSI')\n",
    "from KNMI_readers import read_knmi_uurgeg\n",
    "\n",
    "\n",
    "import puv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ossi_data_reader(datafolder):\n",
    "    '''\n",
    "    author: Paul van Wiechen\n",
    "\n",
    "    Function to read all WLOG_XXX files in a certain subfolder.\n",
    "    Make sure that only WLOG_XXX files are in this folder and no other files.\n",
    "    Only WLOG_XXX files with minimally 2 rows are appended to the dataframe.\n",
    "    A correct WLOG_XXX file should contain a first line with OSSI configuration, and a second line (third row) with starting time\n",
    "    Timestep and sampling frequency are retrieved from the first row. Starting time from the next row\n",
    "    Returns a dataframe with a time column and pressure column in dbars\n",
    "    '''\n",
    "\n",
    "    ossi = pd.DataFrame({\n",
    "        't': [],\n",
    "        'p': []})\n",
    "\n",
    "    directory = str(datafolder)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            print('Currently concatenating file ' + f)\n",
    "            ossi_raw = pd.read_csv(f, header=None, nrows=4, sep=',')\n",
    "            if len(ossi_raw.index) > 2:\n",
    "                t_0 = datetime(int(str(20) + ossi_raw[0][1][1:]), int(ossi_raw[1][1][1:]), int(ossi_raw[2][1][1:]),\n",
    "                               int(ossi_raw[3][1][1:]), int(ossi_raw[4][1][1:]), int(ossi_raw[5][1][1:]))\n",
    "                dt = 1 / float(ossi_raw[6][0][1:])\n",
    "                ossi_tot = pd.read_csv(f, skiprows=3, usecols=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], header=None,\n",
    "                                       sep=',', skipinitialspace=True).to_numpy().flatten()\n",
    "                ossi_temp = pd.DataFrame({\n",
    "                    't': np.array([t_0 + timedelta(seconds=dt * i) for i in range(len(ossi_tot))]),\n",
    "                    'p': ossi_tot})\n",
    "\n",
    "                ossi_temp.dropna(inplace=True)\n",
    "                ossi_temp['p'] = ossi_temp['p'] * 1e5  # Bar to Pa\n",
    "\n",
    "                ossi = pd.concat([ossi, ossi_temp], ignore_index=True)\n",
    "\n",
    "    ossi['p'] = pd.to_numeric(ossi['p'])\n",
    "    ossi['t'] = pd.to_datetime(ossi['t'])\n",
    "\n",
    "    return ossi.set_index('t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently concatenating file C:\\Users\\ruro\\OneDrive - Boskalis\\Documents\\python\\01-Fieldwork\\Pressure_sensors\\OSSI\\OSSI_02_data\\Ossi02_25-27\\WLOG_001.CSV\n",
      "Currently concatenating file C:\\Users\\ruro\\OneDrive - Boskalis\\Documents\\python\\01-Fieldwork\\Pressure_sensors\\OSSI\\OSSI_02_data\\Ossi02_25-27\\WLOG_002.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruro\\AppData\\Local\\Temp\\ipykernel_16016\\1382462514.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ossi = pd.concat([ossi, ossi_temp], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently concatenating file C:\\Users\\ruro\\OneDrive - Boskalis\\Documents\\python\\01-Fieldwork\\Pressure_sensors\\OSSI\\OSSI_02_data\\Ossi02_25-27\\WLOG_003.CSV\n",
      "Currently concatenating file C:\\Users\\ruro\\OneDrive - Boskalis\\Documents\\python\\01-Fieldwork\\Pressure_sensors\\OSSI\\OSSI_02_data\\Ossi02_25-27\\WLOG_004.CSV\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\ruro\\\\OneDrive - Boskalis\\\\Documents\\\\python\\\\01-Fieldwork\\\\Pressure_sensors\\\\OSSI\\\\OSSI_02_data\\\\raw_netcdf\\\\OSSI_02.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\backends\\file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\backends\\lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('C:\\\\Users\\\\ruro\\\\OneDrive - Boskalis\\\\Documents\\\\python\\\\01-Fieldwork\\\\Pressure_sensors\\\\OSSI\\\\OSSI_02_data\\\\raw_netcdf\\\\OSSI_02.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '742c4ae0-7da7-44e4-a759-03a2a0d49afd']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(experimentFolder,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     47\u001b[0m ncFilePath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(experimentFolder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m, instrument \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mncFilePath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\core\\dataset.py:2329\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[1;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[0;32m   2326\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2327\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[1;32m-> 2329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[0;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2337\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2340\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\backends\\api.py:1343\u001b[0m, in \u001b[0;36mto_netcdf\u001b[1;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[0;32m   1339\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1340\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1341\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized option \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1342\u001b[0m         )\n\u001b[1;32m-> 1343\u001b[0m store \u001b[38;5;241m=\u001b[39m store_open(target, mode, \u001b[38;5;28mformat\u001b[39m, group, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unlimited_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1346\u001b[0m     unlimited_dims \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mencoding\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlimited_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:408\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[1;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[0;32m    402\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    403\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m    404\u001b[0m )\n\u001b[0;32m    405\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[0;32m    406\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[0;32m    407\u001b[0m )\n\u001b[1;32m--> 408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:355\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[1;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:417\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:411\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[0;32m    412\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\backends\\file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[1;32mc:\\Users\\ruro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\backends\\file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[1;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opener(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2521\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2158\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\ruro\\\\OneDrive - Boskalis\\\\Documents\\\\python\\\\01-Fieldwork\\\\Pressure_sensors\\\\OSSI\\\\OSSI_02_data\\\\raw_netcdf\\\\OSSI_02.nc'"
     ]
    }
   ],
   "source": [
    "experimentFolder = r\"C:\\Users\\ruro\\OneDrive - Boskalis\\Documents\\python\\01-Fieldwork\\Pressure_sensors\\OSSI\\OSSI_02_data\"    #Grand map\n",
    "dfp = ossi_data_reader(os.path.join(experimentFolder,'Ossi02_25-27'))                                                       #specific map for data OSSI\n",
    "\n",
    "instrument = 'OSSI_02'          # Specific name instrument\n",
    "sf = 10                          # Hz, sampling frequency\n",
    "xRD = 117221.8                   # location x-coord\n",
    "yRD = 559793.1                   # location y-coord\n",
    "serial_number = '18.09.00.08'    # unique serial number\n",
    "\n",
    "rho = 1028      # Density of sea water\n",
    "g = 9.81        # Gravitational force\n",
    "zb = -1.43      # Height of sea bed\n",
    "zi = -1.30      # Height of instrument\n",
    "\n",
    "knmiFile = r\"C:\\Users\\ruro\\OneDrive - Boskalis\\Documents\\python\\01-Fieldwork\\uurgeg_330_2021-2030.txt\"\n",
    "\n",
    "ds = dfp.to_xarray()\n",
    "ds['p'] = ds.p.astype('int32')\n",
    "ds.p.attrs = {'long_name': 'pressure', 'units': 'Pa'}\n",
    "\n",
    "# add global attribute metadata\n",
    "ds.attrs = {\n",
    "    'Conventions': 'CF-1.6',\n",
    "    'name': '{}'.format(instrument),\n",
    "    'instrument': '{}'.format(instrument),\n",
    "    'instrument type': 'OSSI',\n",
    "    'instrument serial number': '{}'.format(serial_number),\n",
    "    'epsg': 28992,\n",
    "    'x': xRD,\n",
    "    'y': yRD,\n",
    "    'sf': 10,\n",
    "    'time zone': 'UTC+2',\n",
    "    'summary': 'SEDMEX field campaign',\n",
    "    'contact person': 'Marlies van der Lugt',\n",
    "    'emailadres': 'm.a.vanderlugt@tudelft.nl',\n",
    "    'construction datetime': datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S)\"),\n",
    "    'version': 'v1',\n",
    "    'version comments': 'constructed with xarray'}\n",
    "\n",
    "#if nothing else, at least specify lossless zlib compression\n",
    "comp = dict(zlib=True, complevel=5)\n",
    "ds.encoding = {var: comp for var in ds.data_vars}\n",
    "\n",
    "# save to file\n",
    "if not os.path.isdir(os.path.join(experimentFolder,'raw_netcdf')):\n",
    "    os.mkdir(os.path.join(experimentFolder,'raw_netcdf'))\n",
    "ncFilePath = os.path.join(experimentFolder, 'raw_netcdf', instrument + '.nc')\n",
    "ds.to_netcdf(ncFilePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = os.path.join(experimentFolder,'raw_netcdf', instrument +'.nc')\n",
    "ds0 = xr.open_dataset(dataFile)\n",
    "instr = ds0.instrument\n",
    "\n",
    "# correct for the air pressure fluctuations and drift in the instrument\n",
    "# first we load the data and add it to the dataset\n",
    "dfp = read_knmi_uurgeg(knmiFile, 330)           # Adjust station number\n",
    "\n",
    "dt = ((ds0.t[1] - ds0.t[0]) / np.timedelta64(1, 's')).values # target frequency\n",
    "\n",
    "pAir = dfp['P'].to_xarray().sel(t=slice(ds0.t.min(), ds0.t.max())).resample({'t': '{}S'.format(dt)}).interpolate('linear')\n",
    "ds0['pAir'] = pAir.sel(t=slice(ds0.t.min(), ds0.t.max()))\n",
    "\n",
    "pAir = dfp['P'].to_xarray().sel(t=slice(ds0.t.min(), ds0.t.max())).resample({'t': '{}S'.format(dt)}).interpolate('linear')\n",
    "ds0['pAir'] = pAir.sel(t=slice(ds0.t.min(), ds0.t.max()))\n",
    "\n",
    "first_real_value = ds0['pAir'].dropna(dim='t', how='all').isel(t=0)\n",
    "# we correct for drift in air pressure, nothing else\n",
    "ds0['dpAir'] = ds0['pAir'] - first_real_value\n",
    "\n",
    "# correct the pressure signal with dpAir and with drift in instrument pressure\n",
    "ds0['pc'] = ds0['p'] -ds0['p'].min() - ds0['dpAir']\n",
    "# ds0['pc'] = ds0['p'] -ds0['p'].min()\n",
    "ds0['pc'].attrs = {'units': 'Pa + NAP', 'long_name': 'pressure', 'comments': 'drift in air pressure is corrected'}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# reshape to one row per burst in data array\n",
    "pt = ds0.pc.values\n",
    "nSamples = len(pt)\n",
    "dt = ds0.isel(t=1).t - ds0.isel(t=0).t\n",
    "sf = np.timedelta64(1, 's') / dt.values\n",
    "\n",
    "burstDuration = pd.Timedelta('1200S')\n",
    "burstLength = int(burstDuration / dt)\n",
    "nBursts = int(np.floor(nSamples / burstLength))\n",
    "\n",
    "pt = pt[:nBursts * burstLength]\n",
    "t = ds0.t[::burstLength]\n",
    "t = t[:nBursts]\n",
    "N = (ds0.t.values[:burstLength] - ds0.t.values[0]) / np.timedelta64(1, 's')\n",
    "# pdb.set_trace()\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# cast into a 2D array\n",
    "ds = xr.Dataset(data_vars={},\n",
    "                coords={'t': t, 'N': N})\n",
    "# copy all data over into this new structure\n",
    "ds['p'] = (('t', 'N'), pt.reshape((nBursts, burstLength)))\n",
    "ds['zi'] = zi\n",
    "ds['zb'] = zb\n",
    "ds['sf'] = sf\n",
    "\n",
    "# remove all bursts where instrument fell dry\n",
    "ds['p'] = ds.p.where(ds.p.std(dim='N') > 70)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# pdb.set_trace()\n",
    "ds['p'].attrs = {'units': 'Pa +NAP', 'long_name': 'pressure', 'comments': 'corrected for air pressure'}\n",
    "ds['zi'].attrs = {'units': 'm+NAP', 'long_name': 'zi'}\n",
    "ds['zb'].attrs = {'units': 'm+NAP', 'long_name': 'zb'}\n",
    "ds['sf'].attrs = {'units': 'Hz', 'long_name': 'sampling frequency'}\n",
    "ds.attrs = ds0.attrs\n",
    "ds.attrs['summary'] = 'SEDMEX field campaign, pressure corrected for air pressure and cast in bursts of 10 minutes'\n",
    "ds['name'] = instr\n",
    "if not os.path.isdir(os.path.join(experimentFolder, 'QC')):\n",
    "    os.mkdir(os.path.join(experimentFolder,'QC'))\n",
    "ncFilePath = os.path.join(experimentFolder, 'QC', instr + '.nc')\n",
    "ds.to_netcdf(ncFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.p.plot()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds0.dpAir.plot()\n",
    "ds0.dpAir.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1/1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% input specification\n",
    "# experimentFolder = r'c:\\Users\\marliesvanderl\\phd\\vakbegeleiding\\CIE5318\\2022\\OSSI\\data'\n",
    "instrFile = os.path.join(experimentFolder,'QC', instrument +'.nc')\n",
    "ncOutFile = os.path.join(experimentFolder,'tailored', instrument +'.nc')\n",
    "\n",
    "# frequency resolution in fourier space\n",
    "### delta_f = p_blocks/D_timeframe ###\n",
    "p_blocks = 20 \n",
    "fresolution = 0.0166\n",
    "# fresolution = 0.03125  #original\n",
    "\n",
    "# %% load the raw data from netcdf\n",
    "ds0 = xr.open_dataset(instrFile)\n",
    "\n",
    "#let's remove the bursts where there are only nans\n",
    "ds0 = ds0.dropna(dim='t')\n",
    "\n",
    "# make a new dataset that has an extra dimension to accomodate for the frequency axis\n",
    "ds = xr.Dataset(data_vars={},\n",
    "                coords={'t': ds0.t.values,\n",
    "                        'N': ds0.N.values,\n",
    "                        'f': np.arange(0, ds0.sf.values / 2, fresolution)})\n",
    "ds['f'].attrs = {'units': 'Hz'}\n",
    "ds.attrs = ds0.attrs\n",
    "\n",
    "# put all variables in this new dataset\n",
    "for key in ds0.data_vars:\n",
    "    ds[key] = ds0[key]\n",
    "\n",
    "# extract sampling frequency as explicit variable\n",
    "sf = ds.f.values\n",
    "\n",
    "# compute water depth\n",
    "ds['h'] = (ds['p']/rho/g + ( ds['zi']-ds['zb'] )).mean(dim='N')\n",
    "ds['h'].attrs = {'long_name': 'mean water level', 'units': 'm+NAP'}\n",
    "\n",
    "# %% do several wave statistics computations, only based on pressure\n",
    "ufunc = lambda x, h: puv.attenuation_corrected_wave_spectrum(\n",
    "    'pressure',\n",
    "    ds.sf.values, x, h,\n",
    "    ds.zi.values,\n",
    "    ds.zb.values,\n",
    "    fresolution=fresolution)\n",
    "\n",
    "fx, ds['vy'] = xr.apply_ufunc(ufunc,\n",
    "                              ds['p'], ds['h'],\n",
    "                              input_core_dims=[['N'], []],\n",
    "                              output_core_dims=[['f'], ['f']],\n",
    "                              vectorize=True)\n",
    "ds['vy'].attrs = {'units': 'm2/Hz', 'long_name': 'spectral density'}\n",
    "\n",
    "ufunc = lambda vy: puv.get_peak_frequency(ds.f.values, vy)\n",
    "ds['fp'] = xr.apply_ufunc(ufunc,\n",
    "                          ds['vy'],\n",
    "                          input_core_dims=[['f']],\n",
    "                          output_core_dims=[[]],\n",
    "                          vectorize=True)\n",
    "\n",
    "\n",
    "ufunc = lambda vy, fp: puv.compute_wave_params(ds.f.values, vy, fmin=0.5 * fp, fmax=5)\n",
    "ds['Hm0'], ds['Tp'], ds['Tm01'], ds['Tm02'], ds['Tmm10'], ds['Tps'] = xr.apply_ufunc(ufunc,\n",
    "                                                                          ds['vy'], ds['fp'],\n",
    "                                                                          input_core_dims=[['f'], []],\n",
    "                                                                          output_core_dims=[[], [], [], [], [], []],\n",
    "                                                                          vectorize=True)\n",
    "\n",
    "# Calculate Hm0 for low frequency waves\n",
    "ufunc = lambda vy, fp: puv.compute_wave_params(ds.f.values, vy, fmin= 10E-4, fmax=0.05)\n",
    "ds['vylf'] = ds.vy.where(ds.f <= 0.05)\n",
    "ds['Hm0_LF'], _, _, _, _, _ = xr.apply_ufunc(ufunc,\n",
    "                                             ds['vy'], ds['fp'],\n",
    "                                             input_core_dims=[['f'], []],\n",
    "                                             output_core_dims=[[], [], [], [], [], []],\n",
    "                                             vectorize=True)\n",
    "\n",
    "# Calculate Hm0 for high frequency waves\n",
    "ufunc = lambda vy, fp: puv.compute_wave_params(ds.f.values, vy, fmin=0.05, fmax=5)\n",
    "# ds['vyhf'] = ds.vy.where(ds.f >= 0.05)\n",
    "ds['Hm0_HF'], _, _, _, _, _ = xr.apply_ufunc(ufunc,\n",
    "                                             ds['vy'], ds['fp'],\n",
    "                                             input_core_dims=[['f'], []],\n",
    "                                             output_core_dims=[[], [], [], [], [], []],\n",
    "                                             vectorize=True)\n",
    "\n",
    "ds['Hm0'].attrs = {'units': 'm', 'long_name': 'significant wave height',\n",
    "                   'computation': 'computed between fmin=0.5fp and fmax=5'}\n",
    "ds['Hm0_LF'].attrs = {'units': 'm', 'long_name': 'significant wave height for low frequency waves (long waves)',\n",
    "                   'computation': 'computed between fmin=0.01 and fmax=0.05'}\n",
    "ds['Hm0_HF'].attrs = {'units': 'm', 'long_name': 'significant wave height for high frequency waves (short waves)',\n",
    "                   'computation': 'computed between fmin=0.05 and fmax=5'}\n",
    "ds['Tp'].attrs = {'units': 's', 'long_name': 'peak wave period',\n",
    "                  'computation': 'computed between fmin=0.5fp and fmax=5'}\n",
    "ds['Tm01'].attrs = {'units': 's', 'long_name': 'mean wave period',\n",
    "                    'computation': 'computed between fmin=0.5fp and fmax=5'}\n",
    "ds['Tm02'].attrs = {'units': 's', 'long_name': 'mean wave period',\n",
    "                    'computation': 'computed between fmin=0.5fp and fmax=5'}\n",
    "ds['Tmm10'].attrs = {'units': 's', 'long_name': 'mean wave period',\n",
    "                     'computation': 'computed between fmin=0.5fp and fmax=5'}\n",
    "ds['Tps'].attrs = {'units': 's', 'long_name': 'smoothed peak period', \n",
    "                     'computation': 'computed between fmin=0.5fp and fmax=5'}\n",
    "\n",
    "# %% write to file\n",
    "# we strip all information on burst scale from the dataset to reduce size (and this info is already present in the raw_netcdf version of the data)\n",
    "dsTailored = ds.drop_dims('N')\n",
    "if not os.path.isdir(os.path.join(experimentFolder,'tailored')):\n",
    "    os.mkdir(os.path.join(experimentFolder,'tailored'))\n",
    "ncFilePath = os.path.join(experimentFolder, 'tailored', ds0.instrument + '.nc')\n",
    "dsTailored.to_netcdf(ncFilePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Hm0_HF.plot()\n",
    "print(ds.vyhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcmoments(fx, vy, fmin=-9999, fmax=9999):\n",
    "    \"\"\"\n",
    "    Calculates spectral moments from frequency and power density data.\n",
    "    \"\"\"    \n",
    "    if np.min(np.diff(fx)) <= 0:\n",
    "        raise ValueError('fx should be increasing')\n",
    "    \n",
    "    imin = bisect(fx, fmin)\n",
    "    imax = bisect(fx, fmax)\n",
    "    \n",
    "    # Select frequency and power density in the specified range\n",
    "    fsel = fx[imin:imax]\n",
    "    vsel = vy[imin:imax]\n",
    "    \n",
    "    # Check if fsel or vsel has only one element (imin == imax case)\n",
    "    if len(fsel) <= 1 or len(vsel) <= 1:\n",
    "        if len(fsel) == 0 or len(vsel) == 0:\n",
    "            # If no values in range, return NaN or zero moments\n",
    "            return pd.DataFrame({'mm2': np.nan, 'mm1': np.nan, 'm0': np.nan, \n",
    "                                 'm1': np.nan, 'm2': np.nan, 'm3': np.nan, 'm4': np.nan}, index=[0])\n",
    "        \n",
    "        # Single-point approximation\n",
    "        f_single = fsel[0]\n",
    "        v_single = vsel[0]\n",
    "        \n",
    "        # Calculate each moment directly as a product\n",
    "        m0 = v_single * (f_single ** 0)\n",
    "        m1 = v_single * (f_single ** 1)\n",
    "        m2 = v_single * (f_single ** 2)\n",
    "        m3 = v_single * (f_single ** 3)\n",
    "        m4 = v_single * (f_single ** 4)\n",
    "        mm1 = v_single * (f_single ** -1)\n",
    "        mm2 = v_single * (f_single ** -2)\n",
    "    else:\n",
    "        # Normal case: integrate over multiple points\n",
    "        if fsel[0] == 0:\n",
    "            fsel = fsel[1:]\n",
    "            vsel = vsel[1:]\n",
    "        \n",
    "        m0 = np.trapz(vsel * (fsel ** 0), fsel)\n",
    "        m1 = np.trapz(vsel * (fsel ** 1), fsel)\n",
    "        m2 = np.trapz(vsel * (fsel ** 2), fsel)\n",
    "        m3 = np.trapz(vsel * (fsel ** 3), fsel)\n",
    "        m4 = np.trapz(vsel * (fsel ** 4), fsel)\n",
    "        mm1 = np.trapz(vsel * (fsel ** -1), fsel)\n",
    "        mm2 = np.trapz(vsel * (fsel ** -2), fsel)\n",
    "    \n",
    "    moments = pd.DataFrame({'mm2': mm2, 'mm1': mm1, 'm0': m0, 'm1': m1, 'm2': m2, 'm3': m3, 'm4': m4}, index=[0])\n",
    "    \n",
    "    return moments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.vy.plot()\n",
    "plt.xlim([1e-3, 1])\n",
    "# plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.vy.plot()\n",
    "plt.xlim([1e-3, 1])\n",
    "# plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific slice of ds.vy (e.g., the first slice)\n",
    "vy_slice = ds.vy.isel(t=60)\n",
    "print(ds.t[60])\n",
    "# Plot the data\n",
    "plt.figure()\n",
    "plt.plot(ds.f, vy_slice)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Spectral Density (m2/Hz)')\n",
    "plt.title('Spectral Density vs Frequency')\n",
    "# plt.xlim(0,2)\n",
    "plt.xscale('log')\n",
    "plt.axvline(0.05, color='red')\n",
    "plt.axvline(0.02925, color='black') # frequency resolution\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
